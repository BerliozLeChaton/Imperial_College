{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICDSS Advanced Data Science Team Challenges 2017-2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author : David JIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CID : 01418670"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import decomposition\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "import xgboost as xgb\n",
    "from PIL import Image\n",
    "import time\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I - Data analyzing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Understanding, normalizing, creating small dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first try to understand the datas : 60000 images in the training set and 10000 in the testing set. We need to classify them into 10 different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reader import get_images\n",
    "(x_train, y_train), (x_test, y_test) = get_images() \n",
    "print'X_train shape : ', x_train.shape\n",
    "print'y_train shape : ', y_train.shape\n",
    "print'X_test shape : ', x_test.shape\n",
    "print'y_test shape : ', y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normalize the datas and we also create a small dataset to work with. We also check that the number of each class in the training set is equivalent, so we have a balanced small training set (6000 datas instead of 60000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape :  (60000, 784)\n",
      "y_train shape :  (60000,)\n",
      "X_test shape :  (10000, 784)\n",
      "y_test shape :  (10000,)\n",
      "[9 0 0 ..., 6 7 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe5f01ef8d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe6282d1b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0\n",
    "x_train_small = x_train[:6000]\n",
    "y_train_small = y_train[:6000]\n",
    "x_test_small = x_test[:1000]\n",
    "y_test_small = y_test[:1000]\n",
    "\n",
    "N_train, d_train = x_train.shape\n",
    "N_test, d_test = x_test.shape\n",
    "plt.imshow(x_train[1].reshape((28,28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Dimension reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main issue with Image Processing is the high dimention of the datas (dimension=784). So we need to reduce it while conserving as much information as we can. Thus, we use 2 methods : PCA and LDA. \n",
    "-  PCA converts a set of observations into a set of linearly uncorrelated variables called principal components. \n",
    "- In LDA, the weights are updated by seeking directions that are efficient for discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "X_proj = pca.fit_transform(x_train[i].reshape(1,-1))\n",
    "X_recons = pca.inverse_transform(X_proj)\n",
    "#plt.imshow(X_recons.reshape((28,28)), cmap='gray')\n",
    "mse = mean_squared_error(x_train[i], np.transpose(X_recons))\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time in 9.683751s\n"
     ]
    }
   ],
   "source": [
    "#PCA dimension reduction\n",
    "start = time.time()\n",
    "pca = decomposition.PCA(n_components=100)\n",
    "pca.fit(x_train)\n",
    "X_reduced_train = pca.transform(x_train)\n",
    "X_reduced_test = pca.transform(x_test)\n",
    "\n",
    "print'Time in %fs' % (time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time in 10.470955s\n"
     ]
    }
   ],
   "source": [
    "#PCA dimension reduction SMALL Dataset\n",
    "start = time.time()\n",
    "pca = decomposition.PCA(n_components=100)\n",
    "pca.fit(x_train)\n",
    "x_train_pca = pca.transform(x_train_small)\n",
    "x_test_pca = pca.transform(x_test_small)\n",
    "\n",
    "print'Time in %fs' % (time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time in 21.480780s\n"
     ]
    }
   ],
   "source": [
    "#LDA dimension reduction\n",
    "start = time.time()\n",
    "lda = LinearDiscriminantAnalysis(n_components=100)\n",
    "lda.fit(x_train, y_train)\n",
    "X_train_lda = lda.transform(x_train)\n",
    "X_test_lda = lda.transform(x_test)\n",
    "\n",
    "print'Time in %fs' % (time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time in 2.521812s\n"
     ]
    }
   ],
   "source": [
    "#LDA dimension reduction SMALL Dataset\n",
    "start = time.time()\n",
    "lda = LinearDiscriminantAnalysis(n_components=100)\n",
    "lda.fit(x_train_small, y_train_small)\n",
    "x_train_lda = lda.transform(x_train_small)\n",
    "x_test_lda = lda.transform(x_test_small)\n",
    "\n",
    "print'Time in %fs' % (time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create more datas to have a larger training set (very useful for deep learning), we did data augmentation by rotating and making symetric images while keeping the same label. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Rotation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe5f013bd90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAD8CAYAAADub8g7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe5f002f410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img1 = x_train[42].reshape((28,28))\n",
    "img2 = np.rot90(img1)\n",
    "img3 = np.rot90(img2)\n",
    "img4 = np.rot90(img3)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.subplot(221)\n",
    "plt.imshow(img1, cmap='gray')\n",
    "plt.subplot(222)\n",
    "plt.imshow(img2, cmap='gray')\n",
    "plt.subplot(223)\n",
    "plt.imshow(img3, cmap='gray')\n",
    "plt.subplot(224)\n",
    "plt.imshow(img4, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Symmetric images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe5f009a090>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCD8QFOEHgiL8QFCEHwiK8ANBEX4gqP8DD4GnxUqTNEkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe5efe93350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img1 = x_train[42].reshape((28,28))\n",
    "imgS1 = np.transpose(img1)\n",
    "imgS2 = np.rot90(imgS1)\n",
    "plt.imshow(imgS2, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe5effde410>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHwiK8ANBEX4gKMIPBPX/y5fIic49mxEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe5f001d350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_trainR1 = np.zeros((N_train,28,28))\n",
    "x_trainR2 = np.zeros((N_train,28,28))\n",
    "x_trainR3 = np.zeros((N_train,28,28))\n",
    "x_trainR4 = np.zeros((N_train,28,28))\n",
    "\n",
    "x_trainS1 = np.zeros((N_train,28,28))\n",
    "x_trainS2 = np.zeros((N_train,28,28))\n",
    "x_trainS3 = np.zeros((N_train,28,28))\n",
    "x_trainS4 = np.zeros((N_train,28,28))\n",
    "\n",
    "for i in range(N_train):\n",
    "    img1 = x_train[i].reshape((28,28))\n",
    "    img2 = np.rot90(img1)\n",
    "    img3 = np.rot90(img2)\n",
    "    img4 = np.rot90(img3)\n",
    "    x_trainR1[i] = img1\n",
    "    x_trainR2[i] = img2\n",
    "    x_trainR3[i] = img3\n",
    "    x_trainR4[i] = img4\n",
    "    x_trainS1[i] = np.transpose(img1)\n",
    "    x_trainS2[i] = np.transpose(img2)\n",
    "    x_trainS3[i] = np.transpose(img3)\n",
    "    x_trainS4[i] = np.transpose(img4)\n",
    "    \n",
    "plt.imshow(x_trainS2[42],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainR1 = y_train\n",
    "y_trainR2 = y_train\n",
    "y_trainR3 = y_train\n",
    "y_trainR4 = y_train\n",
    "\n",
    "y_trainS1 = y_train\n",
    "y_trainS2 = y_train\n",
    "y_trainS3 = y_train\n",
    "y_trainS4 = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Noisy images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have created more images by adding white noise with a low variance, so we can still recognize the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We concatenate the augmented dataset.\n",
    "X_train_da = np.concatenate((x_trainR1,x_trainR2,x_trainR3,x_trainR4,x_trainS1,x_trainS2,x_trainS3,x_trainS4), axis=0)\n",
    "Y_train_da = np.concatenate((y_trainR1,y_trainR2,y_trainR3,y_trainR4,y_trainS1,y_trainS2,y_trainS3,y_trainS4), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II - Sklearn classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(clf, x_train, y_train, x_test, y_test):\n",
    "    start = time.time()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred_train = clf.predict(x_train)\n",
    "    y_pred_test = clf.predict(x_test)\n",
    "    print'Training score : ', accuracy_score(y_train, y_pred_train)\n",
    "    print'Testing score : ', accuracy_score(y_test, y_pred_test)\n",
    "    print'Time in %fs'% (time.time()-start)\n",
    "    \n",
    "    return y_pred_train, y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) LDA Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score :  0.832583333333\n",
      "Testing score :  0.8151\n",
      "Time in 15.698370s\n"
     ]
    }
   ],
   "source": [
    "#Without dimension reduction\n",
    "y_pred_train, y_pred_test = classifier(LinearDiscriminantAnalysis(), x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score :  0.8087\n",
      "Testing score :  0.7993\n",
      "Time in 1.598523s\n"
     ]
    }
   ],
   "source": [
    "#With PCA reduction\n",
    "y_pred_train, y_pred_test = classifier(LinearDiscriminantAnalysis(), X_reduced_train, y_train, X_reduced_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score :  0.832583333333\n",
      "Testing score :  0.8151\n",
      "Time in 0.126806s\n"
     ]
    }
   ],
   "source": [
    "#With LDA reduction\n",
    "y_pred_train2, y_pred_test2 = classifier(LinearDiscriminantAnalysis(), X_train_lda, y_train, X_test_lda, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) SVM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score :  0.959833333333\n",
      "Testing score :  0.812\n",
      "Time in 10.224273s\n"
     ]
    }
   ],
   "source": [
    "#Without dimension reduction\n",
    "y_pred_train, y_pred_test = classifier(LinearSVC(), x_train_small, y_train_small, x_test_small, y_test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score :  0.8665\n",
      "Testing score :  0.833\n",
      "Time in 4.444924s\n"
     ]
    }
   ],
   "source": [
    "#With PCA reduction\n",
    "y_pred_train, y_pred_test = classifier(LinearSVC(), x_train_pca, y_train_small, x_test_pca, y_test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score :  0.8895\n",
      "Testing score :  0.811\n",
      "Time in 0.794078s\n"
     ]
    }
   ],
   "source": [
    "#With LDA reduction\n",
    "y_pred_train2, y_pred_test2 = classifier(LinearSVC(), x_train_lda, y_train_small, x_test_lda, y_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Bayesian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score :  0.783333333333\n",
      "Testing score :  0.77\n",
      "Time in 0.061117s\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "#With PCA reduction\n",
    "y_pred_train, y_pred_test = classifier(gnb, x_train_pca, y_train_small, x_test_pca, y_test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score :  0.881166666667\n",
      "Testing score :  0.8\n",
      "Time in 0.014783s\n"
     ]
    }
   ],
   "source": [
    "#With LDA reduction\n",
    "y_pred_train, y_pred_test = classifier(gnb, x_train_lda, y_train_small, x_test_lda, y_test_small)\n",
    "#y_pred_train2, y_pred_test2 = classifier(mnb, X_train_lda, y_train, X_test_lda, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score :  0.5445\n",
      "Testing score :  0.551\n",
      "Time in 1.004667s\n"
     ]
    }
   ],
   "source": [
    "#Without dimension reduction\n",
    "y_pred_train, y_pred_test = classifier(gnb, x_train_small, y_train_small, x_test_small, y_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost is a very popular algorithm using Boosting Trees. Even though it's not optimal with high dimension datas (it can take a long time), the results should be good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score :  1.0\n",
      "Testing score :  0.827\n",
      "Time in 67.982848s\n"
     ]
    }
   ],
   "source": [
    "#With PCA dimension reduction\n",
    "start = time.time()\n",
    "gbm = xgb.XGBClassifier(max_depth=50, n_estimators=100, learning_rate=0.05).fit(x_train_pca, y_train_small)\n",
    "y_pred_train = gbm.predict(x_train_pca)\n",
    "y_pred_test = gbm.predict(x_test_pca)\n",
    "print'Training score : ', accuracy_score(y_train_small, y_pred_train)\n",
    "print'Testing score : ', accuracy_score(y_test_small, y_pred_test)\n",
    "print'Time in %fs'% (time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score :  0.9995\n",
      "Testing score :  0.798\n",
      "Time in 5.634974s\n"
     ]
    }
   ],
   "source": [
    "#With LDA dimension reduction\n",
    "start = time.time()\n",
    "gbm = xgb.XGBClassifier(max_depth=50, n_estimators=100, learning_rate=0.05).fit(x_train_lda, y_train_small)\n",
    "y_pred_train = gbm.predict(x_train_lda)\n",
    "y_pred_test = gbm.predict(x_test_lda)\n",
    "print'Training score : ', accuracy_score(y_train_small, y_pred_train)\n",
    "print'Testing score : ', accuracy_score(y_test_small, y_pred_test)\n",
    "print'Time in %fs'% (time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score :  1.0\n",
      "Testing score :  0.85\n",
      "Time in 188.089623s\n"
     ]
    }
   ],
   "source": [
    "# Without dimension reduction\n",
    "start = time.time()\n",
    "gbm = xgb.XGBClassifier(max_depth=50, n_estimators=100, learning_rate=0.05).fit(x_train_small, y_train_small)\n",
    "y_pred_train = gbm.predict(x_train_small)\n",
    "y_pred_test = gbm.predict(x_test_small)\n",
    "print'Training score : ', accuracy_score(y_train_small, y_pred_train)\n",
    "print'Testing score : ', accuracy_score(y_test_small, y_pred_test)\n",
    "print'Time in %fs'% (time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>           </td><td>PCA Reduction</td><td>LDA Reduction</td><td>Without Reduction</td></tr>\n",
       "<tr><td>Train score</td><td>1.0          </td><td>1.0          </td><td>1.0              </td></tr>\n",
       "<tr><td>Test score </td><td>0.821        </td><td>0.798        </td><td>0.85             </td></tr>\n",
       "<tr><td>Time (in s)</td><td>77           </td><td>6.2          </td><td>182              </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display table for SMALL DATASET\n",
    "table = [[\"\",\"PCA Reduction\",\"LDA Reduction\",\"Without Reduction\"],\n",
    "        [\"Train score\",1.0, 1.0, 1.0],\n",
    "         [\"Test score\",0.821, 0.798, 0.85],\n",
    "         [\"Time (in s)\",77,6.2, 182]]\n",
    "display(HTML(tabulate.tabulate(table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results were quite good, but the model is not well adapted to the problem because trees are very good for structured datas. which isn't the case of Image Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step would be to do ensemble learning and to combine all those different classifiers with a system of votes, to improve the result. However, as there are many datas (60000 trainings), we believe that the best way to have good results is to use deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III - Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks have always shown good performances in Machine Learning problems. However, Image Processing is a high dimension problems, and the time to update weighs can be very long. CNN is anther kind of neural network which has showed excellent results for Image processing and NLP. By adding a pooling layer, we can decrease the dimension of the datas. So we are going to implement one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D, Conv1D\n",
    "from keras.layers.convolutional import MaxPooling2D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# one hot encode outputs\n",
    "# Total datas\n",
    "y_train_hot = np_utils.to_categorical(y_train)\n",
    "y_test_hot = np_utils.to_categorical(y_test)\n",
    "\n",
    "# Small datas\n",
    "y_train_dummies = np_utils.to_categorical(y_train_small)\n",
    "y_test_dummies = np_utils.to_categorical(y_test_small)\n",
    "\n",
    "# Augmented datas\n",
    "y_train_da = np_utils.to_categorical(Y_train_da)\n",
    "\n",
    "num_classes = y_test_hot.shape[1]\n",
    "print(y_train_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28)\n",
      "(10000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "X_train_temp = x_train\n",
    "X_test_temp = x_test\n",
    "X_train_temp2 = x_train_small\n",
    "X_test_temp2 = x_test_small\n",
    "X_train = X_train_temp.ravel().reshape(60000,1,28,28)\n",
    "X_test = X_test_temp.ravel().reshape(10000,1,28,28)\n",
    "X_train_small = X_train_temp2.ravel().reshape(6000,1,28,28)\n",
    "X_test_small = X_test_temp2.ravel().reshape(1000,1,28,28)\n",
    "\n",
    "x_train_da = X_train_da.ravel().reshape(480000,1,28,28)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 28)        280       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 28, 28)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 28)        7084      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 28, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5488)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2810368   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,822,862\n",
      "Trainable params: 2,822,862\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(data_format=\"channels_first\", pool_size=(2, 2))`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, (3, 3), input_shape=(1,28, 28), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(28, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# Compile model\n",
    "epochs = 15\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 1000 samples\n",
      "Epoch 1/15\n",
      "6000/6000 [==============================] - 80s 13ms/step - loss: 0.3466 - acc: 0.8723 - val_loss: 0.3274 - val_acc: 0.8860\n",
      "Epoch 2/15\n",
      "6000/6000 [==============================] - 81s 14ms/step - loss: 0.3264 - acc: 0.8800 - val_loss: 0.3379 - val_acc: 0.8760\n",
      "Epoch 3/15\n",
      "6000/6000 [==============================] - 66s 11ms/step - loss: 0.3003 - acc: 0.8902 - val_loss: 0.3218 - val_acc: 0.8790\n",
      "Epoch 4/15\n",
      "6000/6000 [==============================] - 62s 10ms/step - loss: 0.2912 - acc: 0.8943 - val_loss: 0.3175 - val_acc: 0.8920\n",
      "Epoch 5/15\n",
      "6000/6000 [==============================] - 64s 11ms/step - loss: 0.2678 - acc: 0.9033 - val_loss: 0.3324 - val_acc: 0.8840\n",
      "Epoch 6/15\n",
      "6000/6000 [==============================] - 65s 11ms/step - loss: 0.2590 - acc: 0.9058 - val_loss: 0.3173 - val_acc: 0.8970\n",
      "Epoch 7/15\n",
      "6000/6000 [==============================] - 74s 12ms/step - loss: 0.2382 - acc: 0.9133 - val_loss: 0.3162 - val_acc: 0.8880\n",
      "Epoch 8/15\n",
      "6000/6000 [==============================] - 75s 13ms/step - loss: 0.2289 - acc: 0.9178 - val_loss: 0.3270 - val_acc: 0.8830\n",
      "Epoch 9/15\n",
      "6000/6000 [==============================] - 77s 13ms/step - loss: 0.2176 - acc: 0.9233 - val_loss: 0.3526 - val_acc: 0.8750\n",
      "Epoch 10/15\n",
      "6000/6000 [==============================] - 75s 13ms/step - loss: 0.2089 - acc: 0.9238 - val_loss: 0.3252 - val_acc: 0.8910\n",
      "Epoch 11/15\n",
      "6000/6000 [==============================] - 73s 12ms/step - loss: 0.1887 - acc: 0.9315 - val_loss: 0.3256 - val_acc: 0.8880\n",
      "Epoch 12/15\n",
      "6000/6000 [==============================] - 74s 12ms/step - loss: 0.1819 - acc: 0.9305 - val_loss: 0.3321 - val_acc: 0.8900\n",
      "Epoch 13/15\n",
      "6000/6000 [==============================] - 85s 14ms/step - loss: 0.1712 - acc: 0.9398 - val_loss: 0.3391 - val_acc: 0.8840\n",
      "Epoch 14/15\n",
      "6000/6000 [==============================] - 77s 13ms/step - loss: 0.1638 - acc: 0.9412 - val_loss: 0.3510 - val_acc: 0.8830\n",
      "Epoch 15/15\n",
      "6000/6000 [==============================] - 83s 14ms/step - loss: 0.1590 - acc: 0.9410 - val_loss: 0.3338 - val_acc: 0.8890\n",
      "Time in 1111.950721s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# Fit the model\n",
    "model.fit(X_train_small, y_train_dummies, validation_data=(X_test_small, y_test_dummies), epochs=epochs, batch_size=25)\n",
    "print'Time in %fs' % (time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 96.30%\n",
      "Test accuracy: 88.90%\n",
      "Time in 35.179054s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Evaluation of the model\n",
    "scores1 = model.evaluate(X_train_small, y_train_dummies, verbose=0)\n",
    "scores2 = model.evaluate(X_test_small, y_test_dummies, verbose=0)\n",
    "print(\"Train accuracy: %.2f%%\" % (scores1[1]*100))\n",
    "print(\"Test accuracy: %.2f%%\" % (scores2[1]*100))\n",
    "\n",
    "print'Time in %fs' % (time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Number of Epochs</td><td style=\"text-align: right;\">5   </td><td style=\"text-align: right;\">25   </td><td style=\"text-align: right;\">100   </td></tr>\n",
       "<tr><td>Train score     </td><td style=\"text-align: right;\">0.87</td><td style=\"text-align: right;\"> 0.98</td><td style=\"text-align: right;\">  1   </td></tr>\n",
       "<tr><td>Test score      </td><td style=\"text-align: right;\">0.83</td><td style=\"text-align: right;\"> 0.88</td><td style=\"text-align: right;\">  0.88</td></tr>\n",
       "<tr><td>Time (in min)   </td><td style=\"text-align: right;\">6   </td><td style=\"text-align: right;\">22   </td><td style=\"text-align: right;\">115   </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display table for SMALL DATASET\n",
    "table = [[\"Number of Epochs\", 5, 25, 100],\n",
    "        [\"Train score\",0.87, 0.98, 1.0],\n",
    "         [\"Test score\",0.83, 0.88, 0.88],\n",
    "         [\"Time (in min)\",6, 22, 115]]\n",
    "display(HTML(tabulate.tabulate(table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Number of Epochs</td><td style=\"text-align: right;\">5   </td><td style=\"text-align: right;\">25   </td></tr>\n",
       "<tr><td>Train score     </td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\"> 0.97</td></tr>\n",
       "<tr><td>Test score      </td><td style=\"text-align: right;\">0.89</td><td style=\"text-align: right;\"> 0.92</td></tr>\n",
       "<tr><td>Time (in min)   </td><td style=\"text-align: right;\">6   </td><td style=\"text-align: right;\">22   </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display table for FULL DATASET\n",
    "table = [[\"Number of Epochs\", 5, 25],\n",
    "        [\"Train score\",0.95, 0.97],\n",
    "         [\"Test score\",0.89, 0.92],\n",
    "         [\"Time (in min)\",6, 22]]\n",
    "display(HTML(tabulate.tabulate(table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also calculated the scores for different parameters : \n",
    "- loss function : same results with Adam loss and sgd loss.\n",
    "- number of conv layers : we loose 2% in testing score when we have 1 conv layer instead of 2.\n",
    "- size of selected regions : same results for (2,2), (3,3) or (4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we also used this CNN with the Augmented Datas from I-2), but the results are the same. Need to find a more robust model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and possible improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best result was obtained with a CNN (between 89 and 92% with 25 epochs). After reading several articles, I think the best way to improve the result would be to implement state of the art neural networks with Keras. I would have tried : \n",
    "- different type of resnet.\n",
    "- more recent CNN such as RCNN.\n",
    "<br> <br>\n",
    "Then, after predicting the labels, I would have combining all the different neural networks with a voting system to obtain a new score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

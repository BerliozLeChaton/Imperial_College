{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from sklearn.neighbors import KNeighborsClassifier, DistanceMetric\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "import keras\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>k</th>\n",
       "      <th>l</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.85</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.52</td>\n",
       "      <td>17.8</td>\n",
       "      <td>95</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.46</td>\n",
       "      <td>3.93</td>\n",
       "      <td>1.09</td>\n",
       "      <td>3.63</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.93</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.65</td>\n",
       "      <td>18.6</td>\n",
       "      <td>102</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.52</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.05</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.55</td>\n",
       "      <td>18.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.25</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.05</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.04</td>\n",
       "      <td>12.4</td>\n",
       "      <td>92</td>\n",
       "      <td>2.72</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2.91</td>\n",
       "      <td>7.20</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2.91</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.05</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.10</td>\n",
       "      <td>17.0</td>\n",
       "      <td>107</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.03</td>\n",
       "      <td>5.04</td>\n",
       "      <td>0.88</td>\n",
       "      <td>3.35</td>\n",
       "      <td>885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b      c     d     e     f    g     h     i     j     k     l     m  \\\n",
       "0  1  1  12.85  1.60  2.52  17.8   95  2.48  2.37  0.26  1.46  3.93  1.09   \n",
       "1  1  1  12.93  3.80  2.65  18.6  102  2.41  2.41  0.25  1.98  4.50  1.03   \n",
       "2  1  1  13.05  1.65  2.55  18.0   98  2.45  2.43  0.29  1.44  4.25  1.12   \n",
       "3  1  1  13.05  1.73  2.04  12.4   92  2.72  3.27  0.17  2.91  7.20  1.12   \n",
       "4  1  1  13.05  1.77  2.10  17.0  107  3.00  3.00  0.28  2.03  5.04  0.88   \n",
       "\n",
       "      n     o  \n",
       "0  3.63  1015  \n",
       "1  3.52   770  \n",
       "2  2.51  1105  \n",
       "3  2.91  1150  \n",
       "4  3.35   885  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = list(string.ascii_lowercase)\n",
    "df = pd.read_csv('wine.data.csv', sep=' ', names=alphabet[:15])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((118, 13), (118,), (60, 13), (60,))\n"
     ]
    }
   ],
   "source": [
    "training_data = df[df.a==1]\n",
    "testing_data = df[df.a==2]\n",
    "X = df[df.columns[2:14]]\n",
    "Y = df[df.columns[1]]\n",
    "X_train = preprocessing.normalize(np.array(training_data[training_data.columns[2:15]]), axis=0) #bien choisir ses features\n",
    "X_test = preprocessing.normalize(np.array(testing_data[testing_data.columns[2:15]]), axis=0)\n",
    "y_train = np.array(training_data[training_data.columns[1]] )\n",
    "y_test = np.array(testing_data[testing_data.columns[1]])\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 : k-NN and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclideanDistance(a, b): #good results\n",
    "    dist = 0\n",
    "    for x in range(len(a)):\n",
    "        dist += (a[x]-b[x])**2\n",
    "    return math.sqrt(dist)\n",
    "\n",
    "def crossCorrelation(a, b):\n",
    "    dist = 0\n",
    "    for x in range(len(a)):\n",
    "        dist += a[x]*b[x]\n",
    "    return dist\n",
    "\n",
    "def KullLeibDiv(a, b):\n",
    "    dist = 0\n",
    "    for x in range(len(a)):\n",
    "        dist += a[x]*np.log(a[x]/b[x])\n",
    "    return dist\n",
    "\n",
    "def JenShan(a, b): #good results\n",
    "    M = [(x+y)/2 for x,y in zip(a,b)]\n",
    "    dist1 = KullLeibDiv(a,M)\n",
    "    dist2 = KullLeibDiv(b,M)\n",
    "    dist = dist1 + dist2\n",
    "    return dist\n",
    "        \n",
    "def chiSquare(a, b): #good results\n",
    "    dist = 0\n",
    "    for x in range(len(a)):\n",
    "        dist += 0.5*((a[x]-b[x])**2)/(a[x]+b[x])\n",
    "    return dist\n",
    "\n",
    "def Mahala(a, b): #good results\n",
    "    dist = 0\n",
    "    covariance = cov(a)\n",
    "    diff = [x-y for x,y in zip(a,b)]\n",
    "    print(covariance)\n",
    "    inv = np.linalg.inv(covariance)\n",
    "    dist = np.dot(np.transpose(diff), inv)\n",
    "    dist = np.dot(dist, diff)\n",
    "    return dist\n",
    "\n",
    "def cov(x):\n",
    "    L = len(x)\n",
    "    cov = np.zeros((L,L))\n",
    "    for i in range(L):\n",
    "        for j in range(L):\n",
    "            print(np.cov(x[i], x[j]))\n",
    "            cov[i][j] = np.cov(x[i], x[j])\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHMdxEuEBw3Ecx0nE/wHZx6FdSyumHQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fce767bb290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import operator\n",
    "from collections import Counter\n",
    "\n",
    "def getNeighbors(X_train, y_train, testInstance, k, metric):\n",
    "    distances = []\n",
    "    labels = []\n",
    "    for x in range(len(X_train)):\n",
    "        dist = metric(testInstance, X_train[x])\n",
    "        distances.append(dist)\n",
    "        labels.append(y_train[x])\n",
    "    #distances.sort(key=lambda tup: tup[1])\n",
    "    distances, labels = (list(t) for t in zip(*sorted(zip(distances, labels))))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(labels[x])  \n",
    "    return neighbors\n",
    " \n",
    "#Input : [y[0], y[1], ...] list of labels\n",
    "def getResponse(neighbors):\n",
    "    most_common,num_most_common = Counter(neighbors).most_common(1)[0]\n",
    "    return most_common\n",
    " \n",
    "def main(metric, k):\n",
    "    \n",
    "    # generate predictions\n",
    "    predictions=[]\n",
    "    y_pred_train=[]\n",
    "    for x in range(len(X_test)):\n",
    "        neighbors = getNeighbors(X_train, y_train, X_test[x], k, metric)\n",
    "        result = getResponse(neighbors)\n",
    "        predictions.append(result)\n",
    "    \n",
    "    for x in range(len(X_train)):\n",
    "        neighbors2 = getNeighbors(X_train, y_train, X_train[x], k, metric)\n",
    "        result2 = getResponse(neighbors2)\n",
    "        y_pred_train.append(result2)\n",
    "    #print'Training score for kNN Classifier : ', accuracy_score(y_pred_train, y_train)        \n",
    "    #print'Testing score for kNN Classifier : ', accuracy_score(predictions, y_test)\n",
    "    return accuracy_score(y_pred_train, y_train), accuracy_score(predictions, y_test)\n",
    "\n",
    "training_score = []\n",
    "testing_score = []\n",
    "for k in range(1,50):\n",
    "    score1, score2 = main(JenShan, k)\n",
    "    training_score.append(score1)\n",
    "    testing_score.append(score2)\n",
    "plt.plot(training_score, label='Training score')\n",
    "plt.plot(testing_score, label='Testing score')\n",
    "plt.legend()\n",
    "plt.xlabel('Value of the parameter k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Score for k-NN Classifier with Jensen Shannon distance')\n",
    "plt.savefig('kNN_JS.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  1\n",
      "Training score for kNN Classifier :  1.0\n",
      "Testing score for kNN Classifier :  0.783333333333\n",
      "k =  2\n",
      "Training score for kNN Classifier :  0.974576271186\n",
      "Testing score for kNN Classifier :  0.716666666667\n",
      "k =  3\n",
      "Training score for kNN Classifier :  0.983050847458\n",
      "Testing score for kNN Classifier :  0.816666666667\n",
      "k =  4\n",
      "Training score for kNN Classifier :  0.966101694915\n",
      "Testing score for kNN Classifier :  0.716666666667\n",
      "k =  5\n",
      "Training score for kNN Classifier :  0.974576271186\n",
      "Testing score for kNN Classifier :  0.85\n",
      "k =  6\n",
      "Training score for kNN Classifier :  0.949152542373\n",
      "Testing score for kNN Classifier :  0.766666666667\n",
      "k =  7\n",
      "Training score for kNN Classifier :  0.974576271186\n",
      "Testing score for kNN Classifier :  0.8\n",
      "k =  8\n",
      "Training score for kNN Classifier :  0.966101694915\n",
      "Testing score for kNN Classifier :  0.75\n",
      "k =  9\n",
      "Training score for kNN Classifier :  0.974576271186\n",
      "Testing score for kNN Classifier :  0.8\n",
      "k =  10\n",
      "Training score for kNN Classifier :  0.957627118644\n",
      "Testing score for kNN Classifier :  0.766666666667\n",
      "k =  11\n",
      "Training score for kNN Classifier :  0.966101694915\n",
      "Testing score for kNN Classifier :  0.816666666667\n",
      "k =  12\n",
      "Training score for kNN Classifier :  0.949152542373\n",
      "Testing score for kNN Classifier :  0.8\n",
      "k =  13\n",
      "Training score for kNN Classifier :  0.957627118644\n",
      "Testing score for kNN Classifier :  0.8\n",
      "k =  14\n",
      "Training score for kNN Classifier :  0.932203389831\n",
      "Testing score for kNN Classifier :  0.816666666667\n",
      "k =  15\n",
      "Training score for kNN Classifier :  0.957627118644\n",
      "Testing score for kNN Classifier :  0.816666666667\n",
      "k =  16\n",
      "Training score for kNN Classifier :  0.949152542373\n",
      "Testing score for kNN Classifier :  0.816666666667\n",
      "k =  17\n",
      "Training score for kNN Classifier :  0.949152542373\n",
      "Testing score for kNN Classifier :  0.816666666667\n",
      "k =  18\n",
      "Training score for kNN Classifier :  0.949152542373\n",
      "Testing score for kNN Classifier :  0.8\n",
      "k =  19\n",
      "Training score for kNN Classifier :  0.957627118644\n",
      "Testing score for kNN Classifier :  0.783333333333\n",
      "k =  20\n",
      "Training score for kNN Classifier :  0.949152542373\n",
      "Testing score for kNN Classifier :  0.783333333333\n",
      "k =  21\n",
      "Training score for kNN Classifier :  0.949152542373\n",
      "Testing score for kNN Classifier :  0.8\n",
      "k =  22\n",
      "Training score for kNN Classifier :  0.949152542373\n",
      "Testing score for kNN Classifier :  0.8\n",
      "k =  23\n",
      "Training score for kNN Classifier :  0.949152542373\n",
      "Testing score for kNN Classifier :  0.816666666667\n",
      "k =  24\n",
      "Training score for kNN Classifier :  0.949152542373\n",
      "Testing score for kNN Classifier :  0.8\n",
      "k =  25\n",
      "Training score for kNN Classifier :  0.957627118644\n",
      "Testing score for kNN Classifier :  0.833333333333\n",
      "k =  26\n",
      "Training score for kNN Classifier :  0.949152542373\n",
      "Testing score for kNN Classifier :  0.833333333333\n",
      "k =  27\n",
      "Training score for kNN Classifier :  0.966101694915\n",
      "Testing score for kNN Classifier :  0.816666666667\n",
      "k =  28\n",
      "Training score for kNN Classifier :  0.966101694915\n",
      "Testing score for kNN Classifier :  0.833333333333\n",
      "k =  29\n",
      "Training score for kNN Classifier :  0.966101694915\n",
      "Testing score for kNN Classifier :  0.816666666667\n",
      "k =  30\n",
      "Training score for kNN Classifier :  0.957627118644\n",
      "Testing score for kNN Classifier :  0.816666666667\n",
      "k =  31\n",
      "Training score for kNN Classifier :  0.966101694915\n",
      "Testing score for kNN Classifier :  0.85\n",
      "k =  32\n",
      "Training score for kNN Classifier :  0.957627118644\n",
      "Testing score for kNN Classifier :  0.85\n",
      "k =  33\n",
      "Training score for kNN Classifier :  0.957627118644\n",
      "Testing score for kNN Classifier :  0.85\n",
      "k =  34\n",
      "Training score for kNN Classifier :  0.957627118644\n",
      "Testing score for kNN Classifier :  0.816666666667\n",
      "k =  35\n",
      "Training score for kNN Classifier :  0.957627118644\n",
      "Testing score for kNN Classifier :  0.833333333333\n",
      "k =  36\n",
      "Training score for kNN Classifier :  0.957627118644\n",
      "Testing score for kNN Classifier :  0.85\n",
      "k =  37\n",
      "Training score for kNN Classifier :  0.957627118644\n",
      "Testing score for kNN Classifier :  0.85\n",
      "k =  38\n",
      "Training score for kNN Classifier :  0.957627118644\n",
      "Testing score for kNN Classifier :  0.85\n",
      "k =  39\n",
      "Training score for kNN Classifier :  0.957627118644\n",
      "Testing score for kNN Classifier :  0.85\n",
      "k =  40\n",
      "Training score for kNN Classifier :  0.957627118644\n",
      "Testing score for kNN Classifier :  0.833333333333\n",
      "k =  41\n",
      "Training score for kNN Classifier :  0.957627118644\n",
      "Testing score for kNN Classifier :  0.85\n",
      "k =  42\n",
      "Training score for kNN Classifier :  0.957627118644\n",
      "Testing score for kNN Classifier :  0.85\n",
      "k =  43\n",
      "Training score for kNN Classifier :  0.957627118644\n",
      "Testing score for kNN Classifier :  0.85\n",
      "k =  44\n",
      "Training score for kNN Classifier :  0.957627118644\n",
      "Testing score for kNN Classifier :  0.833333333333\n",
      "k =  45\n",
      "Training score for kNN Classifier :  0.957627118644\n",
      "Testing score for kNN Classifier :  0.833333333333\n",
      "k =  46\n",
      "Training score for kNN Classifier :  0.957627118644\n",
      "Testing score for kNN Classifier :  0.833333333333\n",
      "k =  47\n",
      "Training score for kNN Classifier :  0.949152542373\n",
      "Testing score for kNN Classifier :  0.85\n",
      "k =  48\n",
      "Training score for kNN Classifier :  0.949152542373\n",
      "Testing score for kNN Classifier :  0.833333333333\n",
      "k =  49\n",
      "Training score for kNN Classifier :  0.949152542373\n",
      "Testing score for kNN Classifier :  0.833333333333\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fce766be210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time in 0.459808s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "training_score = []\n",
    "testing_score = []\n",
    "metrics = ['euclidean', 'manhattan', 'chebyshev', 'minkowski']\n",
    "cov_training = np.cov(np.transpose(X_train))\n",
    "for k in range(1,50):\n",
    "    print'k = ',k\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric=metrics[0])#metric='mahalanobis', metric_params={'V': cov_training})\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_train = knn.predict(X_train)\n",
    "    y_pred_test = knn.predict(X_test)\n",
    "    print'Training score for kNN Classifier : ', accuracy_score(y_pred_train, y_train)\n",
    "    print'Testing score for kNN Classifier : ', accuracy_score(y_pred_test, y_test)\n",
    "    training_score.append(accuracy_score(y_pred_train, y_train))\n",
    "    testing_score.append(accuracy_score(y_pred_test, y_test))\n",
    "plt.figure()\n",
    "plt.plot(training_score, label='Training score')\n",
    "plt.plot(testing_score, label='Testing score')\n",
    "plt.legend()\n",
    "plt.xlabel('Value of the parameter k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Score for k-NN Classifier with Euclidean distance')\n",
    "plt.savefig('kNN_eucli.png')\n",
    "plt.show()\n",
    "print'Time in %fs' % (time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 : k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score for k-means :  0.0762711864407\n",
      "Testing score for k-means :  0.183333333333\n",
      "Time in 0.027675s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "training_score = []\n",
    "testing_score = []\n",
    "metrics = ['euclidean', 'manhattan', 'chebyshev', 'minkowski']\n",
    "kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=1000)\n",
    "kmeans.fit(X_train, y_train)\n",
    "y_pred_train = kmeans.predict(X_train)\n",
    "y_pred_test = kmeans.predict(X_test)\n",
    "print'Training score for k-means : ', accuracy_score(y_pred_train, y_train)\n",
    "print'Testing score for k-means : ', accuracy_score(y_pred_test, y_test)\n",
    "training_score.append(accuracy_score(y_pred_train, y_train))\n",
    "testing_score.append(accuracy_score(y_pred_test, y_test))\n",
    "print'Time in %fs' % (time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 : Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score for MLP Classifier :  0.0762711864407\n",
      "Testing score for MLP Classifier :  0.183333333333\n",
      "Time in 0.143006s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "training_score = []\n",
    "testing_score = []\n",
    "solver = ['lbfgs', 'sgd', 'adam']\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred_train = kmeans.predict(X_train)\n",
    "y_pred_test = kmeans.predict(X_test)\n",
    "print'Training score for MLP Classifier : ', accuracy_score(y_pred_train, y_train)\n",
    "print'Testing score for MLP Classifier : ', accuracy_score(y_pred_test, y_test)\n",
    "training_score.append(accuracy_score(y_pred_train, y_train))\n",
    "testing_score.append(accuracy_score(y_pred_test, y_test))\n",
    "print'Time in %fs' % (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "#https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network \n",
    "y_dummies = pd.get_dummies(Y)\n",
    "y_dummies2 = pd.get_dummies(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 748us/step - loss: 1.0869 - acc: 0.3559\n",
      "118/118 [==============================] - 0s 287us/step\n",
      "\n",
      "acc: 43.22%\n",
      "Testing score for Neural Network :  0.35\n",
      "Epoch 1/6\n",
      "118/118 [==============================] - 0s 851us/step - loss: 1.1019 - acc: 0.3051\n",
      "Epoch 2/6\n",
      "118/118 [==============================] - 0s 259us/step - loss: 1.0827 - acc: 0.3814\n",
      "Epoch 3/6\n",
      "118/118 [==============================] - 0s 238us/step - loss: 1.0739 - acc: 0.3644\n",
      "Epoch 4/6\n",
      "118/118 [==============================] - 0s 279us/step - loss: 1.0578 - acc: 0.4661\n",
      "Epoch 5/6\n",
      "118/118 [==============================] - 0s 272us/step - loss: 1.0721 - acc: 0.3559\n",
      "Epoch 6/6\n",
      "118/118 [==============================] - 0s 252us/step - loss: 1.0621 - acc: 0.4322\n",
      "118/118 [==============================] - 0s 445us/step\n",
      "\n",
      "acc: 43.22%\n",
      "Testing score for Neural Network :  0.416666666667\n",
      "Epoch 1/11\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 1.0739 - acc: 0.3983\n",
      "Epoch 2/11\n",
      "118/118 [==============================] - 0s 209us/step - loss: 1.0999 - acc: 0.3136\n",
      "Epoch 3/11\n",
      "118/118 [==============================] - 0s 257us/step - loss: 1.0878 - acc: 0.3475\n",
      "Epoch 4/11\n",
      "118/118 [==============================] - 0s 285us/step - loss: 1.0621 - acc: 0.4153\n",
      "Epoch 5/11\n",
      "118/118 [==============================] - 0s 240us/step - loss: 1.0722 - acc: 0.3898\n",
      "Epoch 6/11\n",
      "118/118 [==============================] - 0s 300us/step - loss: 1.0626 - acc: 0.4237\n",
      "Epoch 7/11\n",
      "118/118 [==============================] - 0s 248us/step - loss: 1.0799 - acc: 0.3644\n",
      "Epoch 8/11\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.9443 - acc: 0.500 - 0s 274us/step - loss: 1.0704 - acc: 0.3898\n",
      "Epoch 9/11\n",
      "118/118 [==============================] - 0s 311us/step - loss: 1.0634 - acc: 0.4068\n",
      "Epoch 10/11\n",
      "118/118 [==============================] - 0s 220us/step - loss: 1.0434 - acc: 0.5000\n",
      "Epoch 11/11\n",
      "118/118 [==============================] - 0s 192us/step - loss: 1.0552 - acc: 0.3559\n",
      "118/118 [==============================] - 0s 561us/step\n",
      "\n",
      "acc: 43.22%\n",
      "Testing score for Neural Network :  0.333333333333\n",
      "Epoch 1/16\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 1.1167 - acc: 0.2881\n",
      "Epoch 2/16\n",
      "118/118 [==============================] - 0s 175us/step - loss: 1.0836 - acc: 0.4153\n",
      "Epoch 3/16\n",
      "118/118 [==============================] - 0s 250us/step - loss: 1.0831 - acc: 0.4237\n",
      "Epoch 4/16\n",
      "118/118 [==============================] - 0s 248us/step - loss: 1.0704 - acc: 0.4831\n",
      "Epoch 5/16\n",
      "118/118 [==============================] - 0s 249us/step - loss: 1.0589 - acc: 0.5339\n",
      "Epoch 6/16\n",
      "118/118 [==============================] - 0s 227us/step - loss: 1.0744 - acc: 0.4661\n",
      "Epoch 7/16\n",
      "118/118 [==============================] - 0s 203us/step - loss: 1.0670 - acc: 0.4322\n",
      "Epoch 8/16\n",
      "118/118 [==============================] - 0s 224us/step - loss: 1.0474 - acc: 0.4661\n",
      "Epoch 9/16\n",
      "118/118 [==============================] - 0s 231us/step - loss: 1.0425 - acc: 0.5085\n",
      "Epoch 10/16\n",
      "118/118 [==============================] - 0s 281us/step - loss: 1.0642 - acc: 0.4661\n",
      "Epoch 11/16\n",
      "118/118 [==============================] - 0s 563us/step - loss: 1.0289 - acc: 0.4915\n",
      "Epoch 12/16\n",
      "118/118 [==============================] - 0s 204us/step - loss: 1.0083 - acc: 0.5339\n",
      "Epoch 13/16\n",
      "118/118 [==============================] - 0s 399us/step - loss: 1.0460 - acc: 0.4746\n",
      "Epoch 14/16\n",
      "118/118 [==============================] - 0s 370us/step - loss: 1.0343 - acc: 0.4915\n",
      "Epoch 15/16\n",
      "118/118 [==============================] - 0s 309us/step - loss: 1.0469 - acc: 0.4661\n",
      "Epoch 16/16\n",
      "118/118 [==============================] - 0s 386us/step - loss: 1.0224 - acc: 0.4661\n",
      "118/118 [==============================] - 0s 864us/step\n",
      "\n",
      "acc: 43.22%\n",
      "Testing score for Neural Network :  0.4\n",
      "Epoch 1/21\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1.1339 - acc: 0.2034\n",
      "Epoch 2/21\n",
      "118/118 [==============================] - 0s 277us/step - loss: 1.1272 - acc: 0.2627\n",
      "Epoch 3/21\n",
      "118/118 [==============================] - 0s 263us/step - loss: 1.1175 - acc: 0.2712\n",
      "Epoch 4/21\n",
      "118/118 [==============================] - 0s 253us/step - loss: 1.1012 - acc: 0.3559\n",
      "Epoch 5/21\n",
      "118/118 [==============================] - 0s 296us/step - loss: 1.1065 - acc: 0.4407\n",
      "Epoch 6/21\n",
      "118/118 [==============================] - 0s 264us/step - loss: 1.0841 - acc: 0.4153\n",
      "Epoch 7/21\n",
      "118/118 [==============================] - 0s 286us/step - loss: 1.0808 - acc: 0.4831\n",
      "Epoch 8/21\n",
      "118/118 [==============================] - 0s 309us/step - loss: 1.0607 - acc: 0.5678\n",
      "Epoch 9/21\n",
      "118/118 [==============================] - 0s 249us/step - loss: 1.0677 - acc: 0.4831\n",
      "Epoch 10/21\n",
      "118/118 [==============================] - 0s 324us/step - loss: 1.0703 - acc: 0.5085\n",
      "Epoch 11/21\n",
      "118/118 [==============================] - 0s 316us/step - loss: 1.0815 - acc: 0.4746\n",
      "Epoch 12/21\n",
      "118/118 [==============================] - 0s 301us/step - loss: 1.0676 - acc: 0.4915\n",
      "Epoch 13/21\n",
      "118/118 [==============================] - 0s 426us/step - loss: 1.0616 - acc: 0.5000\n",
      "Epoch 14/21\n",
      "118/118 [==============================] - 0s 200us/step - loss: 1.0741 - acc: 0.4492\n",
      "Epoch 15/21\n",
      "118/118 [==============================] - 0s 273us/step - loss: 1.0569 - acc: 0.4915\n",
      "Epoch 16/21\n",
      "118/118 [==============================] - 0s 299us/step - loss: 1.0600 - acc: 0.4746\n",
      "Epoch 17/21\n",
      "118/118 [==============================] - 0s 206us/step - loss: 1.0557 - acc: 0.4492\n",
      "Epoch 18/21\n",
      "118/118 [==============================] - 0s 362us/step - loss: 1.0559 - acc: 0.4576\n",
      "Epoch 19/21\n",
      "118/118 [==============================] - 0s 378us/step - loss: 1.0475 - acc: 0.4915\n",
      "Epoch 20/21\n",
      "118/118 [==============================] - 0s 308us/step - loss: 1.0542 - acc: 0.4746\n",
      "Epoch 21/21\n",
      "118/118 [==============================] - 0s 315us/step - loss: 1.0340 - acc: 0.4661\n",
      "118/118 [==============================] - 0s 989us/step\n",
      "\n",
      "acc: 43.22%\n",
      "Testing score for Neural Network :  0.4\n",
      "Epoch 1/26\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1.1070 - acc: 0.3220\n",
      "Epoch 2/26\n",
      "118/118 [==============================] - 0s 131us/step - loss: 1.1054 - acc: 0.3729\n",
      "Epoch 3/26\n",
      "118/118 [==============================] - 0s 255us/step - loss: 1.1080 - acc: 0.3475\n",
      "Epoch 4/26\n",
      "118/118 [==============================] - 0s 180us/step - loss: 1.0887 - acc: 0.4153\n",
      "Epoch 5/26\n",
      "118/118 [==============================] - 0s 200us/step - loss: 1.0698 - acc: 0.4068\n",
      "Epoch 6/26\n",
      "118/118 [==============================] - 0s 240us/step - loss: 1.0830 - acc: 0.4153\n",
      "Epoch 7/26\n",
      "118/118 [==============================] - 0s 158us/step - loss: 1.0717 - acc: 0.3983\n",
      "Epoch 8/26\n",
      "118/118 [==============================] - 0s 203us/step - loss: 1.0529 - acc: 0.4322\n",
      "Epoch 9/26\n",
      "118/118 [==============================] - 0s 275us/step - loss: 1.0371 - acc: 0.4576\n",
      "Epoch 10/26\n",
      "118/118 [==============================] - 0s 145us/step - loss: 1.0584 - acc: 0.4153\n",
      "Epoch 11/26\n",
      "118/118 [==============================] - 0s 252us/step - loss: 1.0442 - acc: 0.4237\n",
      "Epoch 12/26\n",
      "118/118 [==============================] - 0s 175us/step - loss: 1.0479 - acc: 0.4322\n",
      "Epoch 13/26\n",
      "118/118 [==============================] - 0s 176us/step - loss: 1.0419 - acc: 0.4661\n",
      "Epoch 14/26\n",
      "118/118 [==============================] - 0s 260us/step - loss: 1.0491 - acc: 0.3814\n",
      "Epoch 15/26\n",
      "118/118 [==============================] - 0s 183us/step - loss: 1.0566 - acc: 0.4068\n",
      "Epoch 16/26\n",
      "118/118 [==============================] - 0s 201us/step - loss: 1.0277 - acc: 0.4492\n",
      "Epoch 17/26\n",
      "118/118 [==============================] - 0s 202us/step - loss: 1.0263 - acc: 0.4831\n",
      "Epoch 18/26\n",
      "118/118 [==============================] - 0s 192us/step - loss: 1.0204 - acc: 0.4915\n",
      "Epoch 19/26\n",
      "118/118 [==============================] - 0s 238us/step - loss: 1.0037 - acc: 0.4407\n",
      "Epoch 20/26\n",
      "118/118 [==============================] - 0s 192us/step - loss: 0.9993 - acc: 0.4661\n",
      "Epoch 21/26\n",
      "118/118 [==============================] - 0s 251us/step - loss: 1.0137 - acc: 0.4322\n",
      "Epoch 22/26\n",
      "118/118 [==============================] - 0s 242us/step - loss: 1.0070 - acc: 0.4407\n",
      "Epoch 23/26\n",
      "118/118 [==============================] - 0s 308us/step - loss: 0.9990 - acc: 0.4492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/26\n",
      "118/118 [==============================] - 0s 326us/step - loss: 1.0078 - acc: 0.4746\n",
      "Epoch 25/26\n",
      "118/118 [==============================] - 0s 314us/step - loss: 0.9973 - acc: 0.4322\n",
      "Epoch 26/26\n",
      "118/118 [==============================] - 0s 263us/step - loss: 0.9927 - acc: 0.4492\n",
      "118/118 [==============================] - 0s 1ms/step\n",
      "\n",
      "acc: 45.76%\n",
      "Testing score for Neural Network :  0.4\n",
      "Epoch 1/31\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1.0829 - acc: 0.3983\n",
      "Epoch 2/31\n",
      "118/118 [==============================] - 0s 268us/step - loss: 1.0889 - acc: 0.3644\n",
      "Epoch 3/31\n",
      "118/118 [==============================] - 0s 321us/step - loss: 1.0745 - acc: 0.3814\n",
      "Epoch 4/31\n",
      "118/118 [==============================] - 0s 428us/step - loss: 1.0586 - acc: 0.4661\n",
      "Epoch 5/31\n",
      "118/118 [==============================] - 0s 410us/step - loss: 1.0663 - acc: 0.4492\n",
      "Epoch 6/31\n",
      "118/118 [==============================] - 0s 210us/step - loss: 1.0567 - acc: 0.4576\n",
      "Epoch 7/31\n",
      "118/118 [==============================] - 0s 289us/step - loss: 1.0442 - acc: 0.4068\n",
      "Epoch 8/31\n",
      "118/118 [==============================] - 0s 404us/step - loss: 1.0514 - acc: 0.4322\n",
      "Epoch 9/31\n",
      "118/118 [==============================] - 0s 300us/step - loss: 1.0459 - acc: 0.4576\n",
      "Epoch 10/31\n",
      "118/118 [==============================] - 0s 323us/step - loss: 1.0531 - acc: 0.4322\n",
      "Epoch 11/31\n",
      "118/118 [==============================] - 0s 310us/step - loss: 1.0463 - acc: 0.4322\n",
      "Epoch 12/31\n",
      "118/118 [==============================] - 0s 180us/step - loss: 1.0332 - acc: 0.4407\n",
      "Epoch 13/31\n",
      "118/118 [==============================] - 0s 222us/step - loss: 1.0416 - acc: 0.4322\n",
      "Epoch 14/31\n",
      "118/118 [==============================] - 0s 315us/step - loss: 1.0411 - acc: 0.4068\n",
      "Epoch 15/31\n",
      "118/118 [==============================] - 0s 185us/step - loss: 1.0193 - acc: 0.4068\n",
      "Epoch 16/31\n",
      "118/118 [==============================] - 0s 171us/step - loss: 1.0171 - acc: 0.4492\n",
      "Epoch 17/31\n",
      "118/118 [==============================] - 0s 220us/step - loss: 1.0064 - acc: 0.4492\n",
      "Epoch 18/31\n",
      "118/118 [==============================] - 0s 185us/step - loss: 1.0181 - acc: 0.4661\n",
      "Epoch 19/31\n",
      "118/118 [==============================] - 0s 266us/step - loss: 0.9954 - acc: 0.4746\n",
      "Epoch 20/31\n",
      "118/118 [==============================] - 0s 416us/step - loss: 1.0010 - acc: 0.4661\n",
      "Epoch 21/31\n",
      "118/118 [==============================] - 0s 488us/step - loss: 1.0063 - acc: 0.4576\n",
      "Epoch 22/31\n",
      "118/118 [==============================] - 0s 286us/step - loss: 0.9961 - acc: 0.5000\n",
      "Epoch 23/31\n",
      "118/118 [==============================] - 0s 372us/step - loss: 1.0037 - acc: 0.4492\n",
      "Epoch 24/31\n",
      "118/118 [==============================] - 0s 412us/step - loss: 0.9768 - acc: 0.5000\n",
      "Epoch 25/31\n",
      "118/118 [==============================] - 0s 241us/step - loss: 0.9903 - acc: 0.4831\n",
      "Epoch 26/31\n",
      "118/118 [==============================] - 0s 168us/step - loss: 0.9892 - acc: 0.5000\n",
      "Epoch 27/31\n",
      "118/118 [==============================] - 0s 394us/step - loss: 0.9727 - acc: 0.4831\n",
      "Epoch 28/31\n",
      "118/118 [==============================] - 0s 218us/step - loss: 0.9732 - acc: 0.5085\n",
      "Epoch 29/31\n",
      "118/118 [==============================] - 0s 242us/step - loss: 0.9707 - acc: 0.5000\n",
      "Epoch 30/31\n",
      "118/118 [==============================] - 0s 127us/step - loss: 0.9569 - acc: 0.5424\n",
      "Epoch 31/31\n",
      "118/118 [==============================] - 0s 129us/step - loss: 0.9470 - acc: 0.5593\n",
      "118/118 [==============================] - 0s 716us/step\n",
      "\n",
      "acc: 49.15%\n",
      "Testing score for Neural Network :  0.4\n",
      "Epoch 1/36\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.0642 - acc: 0.4576\n",
      "Epoch 2/36\n",
      "118/118 [==============================] - 0s 150us/step - loss: 1.0599 - acc: 0.4576\n",
      "Epoch 3/36\n",
      "118/118 [==============================] - 0s 152us/step - loss: 1.0432 - acc: 0.4492\n",
      "Epoch 4/36\n",
      "118/118 [==============================] - 0s 132us/step - loss: 1.0512 - acc: 0.4153\n",
      "Epoch 5/36\n",
      "118/118 [==============================] - 0s 122us/step - loss: 1.0573 - acc: 0.3898\n",
      "Epoch 6/36\n",
      "118/118 [==============================] - 0s 126us/step - loss: 1.0568 - acc: 0.4237\n",
      "Epoch 7/36\n",
      "118/118 [==============================] - 0s 120us/step - loss: 1.0429 - acc: 0.4746\n",
      "Epoch 8/36\n",
      "118/118 [==============================] - 0s 143us/step - loss: 1.0443 - acc: 0.4661\n",
      "Epoch 9/36\n",
      "118/118 [==============================] - 0s 148us/step - loss: 1.0353 - acc: 0.4407\n",
      "Epoch 10/36\n",
      "118/118 [==============================] - 0s 142us/step - loss: 1.0249 - acc: 0.4492\n",
      "Epoch 11/36\n",
      "118/118 [==============================] - 0s 139us/step - loss: 1.0209 - acc: 0.4492\n",
      "Epoch 12/36\n",
      "118/118 [==============================] - 0s 144us/step - loss: 1.0177 - acc: 0.4661\n",
      "Epoch 13/36\n",
      "118/118 [==============================] - 0s 156us/step - loss: 1.0263 - acc: 0.4492\n",
      "Epoch 14/36\n",
      "118/118 [==============================] - 0s 142us/step - loss: 1.0255 - acc: 0.4153\n",
      "Epoch 15/36\n",
      "118/118 [==============================] - 0s 151us/step - loss: 1.0260 - acc: 0.4492\n",
      "Epoch 16/36\n",
      "118/118 [==============================] - 0s 163us/step - loss: 0.9924 - acc: 0.4576\n",
      "Epoch 17/36\n",
      "118/118 [==============================] - 0s 143us/step - loss: 1.0022 - acc: 0.4576\n",
      "Epoch 18/36\n",
      "118/118 [==============================] - 0s 132us/step - loss: 0.9967 - acc: 0.4576\n",
      "Epoch 19/36\n",
      "118/118 [==============================] - 0s 139us/step - loss: 1.0014 - acc: 0.4407\n",
      "Epoch 20/36\n",
      "118/118 [==============================] - 0s 132us/step - loss: 0.9920 - acc: 0.4915\n",
      "Epoch 21/36\n",
      "118/118 [==============================] - 0s 131us/step - loss: 0.9927 - acc: 0.4661\n",
      "Epoch 22/36\n",
      "118/118 [==============================] - 0s 131us/step - loss: 0.9812 - acc: 0.4831\n",
      "Epoch 23/36\n",
      "118/118 [==============================] - 0s 135us/step - loss: 0.9718 - acc: 0.5085\n",
      "Epoch 24/36\n",
      "118/118 [==============================] - 0s 142us/step - loss: 0.9847 - acc: 0.4915\n",
      "Epoch 25/36\n",
      "118/118 [==============================] - 0s 148us/step - loss: 0.9680 - acc: 0.5763\n",
      "Epoch 26/36\n",
      "118/118 [==============================] - 0s 142us/step - loss: 0.9558 - acc: 0.5424\n",
      "Epoch 27/36\n",
      "118/118 [==============================] - 0s 147us/step - loss: 0.9544 - acc: 0.5169\n",
      "Epoch 28/36\n",
      "118/118 [==============================] - 0s 130us/step - loss: 0.9572 - acc: 0.5424\n",
      "Epoch 29/36\n",
      "118/118 [==============================] - 0s 140us/step - loss: 0.9489 - acc: 0.5254\n",
      "Epoch 30/36\n",
      "118/118 [==============================] - 0s 145us/step - loss: 0.9349 - acc: 0.5508\n",
      "Epoch 31/36\n",
      "118/118 [==============================] - 0s 137us/step - loss: 0.9521 - acc: 0.5339\n",
      "Epoch 32/36\n",
      "118/118 [==============================] - 0s 146us/step - loss: 0.9220 - acc: 0.6102\n",
      "Epoch 33/36\n",
      "118/118 [==============================] - 0s 137us/step - loss: 0.9166 - acc: 0.5932\n",
      "Epoch 34/36\n",
      "118/118 [==============================] - 0s 154us/step - loss: 0.9135 - acc: 0.5763\n",
      "Epoch 35/36\n",
      "118/118 [==============================] - 0s 165us/step - loss: 0.9184 - acc: 0.5593\n",
      "Epoch 36/36\n",
      "118/118 [==============================] - 0s 160us/step - loss: 0.8979 - acc: 0.6102\n",
      "118/118 [==============================] - 0s 739us/step\n",
      "\n",
      "acc: 62.71%\n",
      "Testing score for Neural Network :  0.533333333333\n",
      "Epoch 1/41\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1.1300 - acc: 0.2119\n",
      "Epoch 2/41\n",
      "118/118 [==============================] - 0s 147us/step - loss: 1.0986 - acc: 0.3220\n",
      "Epoch 3/41\n",
      "118/118 [==============================] - 0s 144us/step - loss: 1.0987 - acc: 0.3136\n",
      "Epoch 4/41\n",
      "118/118 [==============================] - 0s 144us/step - loss: 1.0827 - acc: 0.4322\n",
      "Epoch 5/41\n",
      "118/118 [==============================] - 0s 144us/step - loss: 1.0702 - acc: 0.4661\n",
      "Epoch 6/41\n",
      "118/118 [==============================] - 0s 139us/step - loss: 1.0593 - acc: 0.4915\n",
      "Epoch 7/41\n",
      "118/118 [==============================] - 0s 142us/step - loss: 1.0727 - acc: 0.4407\n",
      "Epoch 8/41\n",
      "118/118 [==============================] - 0s 135us/step - loss: 1.0591 - acc: 0.4831\n",
      "Epoch 9/41\n",
      "118/118 [==============================] - 0s 163us/step - loss: 1.0433 - acc: 0.4576\n",
      "Epoch 10/41\n",
      "118/118 [==============================] - 0s 141us/step - loss: 1.0392 - acc: 0.4576\n",
      "Epoch 11/41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 0s 159us/step - loss: 1.0333 - acc: 0.4492\n",
      "Epoch 12/41\n",
      "118/118 [==============================] - 0s 147us/step - loss: 1.0252 - acc: 0.4661\n",
      "Epoch 13/41\n",
      "118/118 [==============================] - 0s 146us/step - loss: 1.0398 - acc: 0.4153\n",
      "Epoch 14/41\n",
      "118/118 [==============================] - 0s 133us/step - loss: 1.0341 - acc: 0.4407\n",
      "Epoch 15/41\n",
      "118/118 [==============================] - 0s 125us/step - loss: 1.0316 - acc: 0.4576\n",
      "Epoch 16/41\n",
      "118/118 [==============================] - 0s 121us/step - loss: 1.0230 - acc: 0.4746\n",
      "Epoch 17/41\n",
      "118/118 [==============================] - 0s 138us/step - loss: 1.0064 - acc: 0.4831\n",
      "Epoch 18/41\n",
      "118/118 [==============================] - 0s 142us/step - loss: 1.0256 - acc: 0.4746\n",
      "Epoch 19/41\n",
      "118/118 [==============================] - 0s 132us/step - loss: 1.0162 - acc: 0.5085\n",
      "Epoch 20/41\n",
      "118/118 [==============================] - 0s 128us/step - loss: 1.0140 - acc: 0.4237\n",
      "Epoch 21/41\n",
      "118/118 [==============================] - 0s 114us/step - loss: 1.0073 - acc: 0.4153\n",
      "Epoch 22/41\n",
      "118/118 [==============================] - 0s 114us/step - loss: 0.9969 - acc: 0.4915\n",
      "Epoch 23/41\n",
      "118/118 [==============================] - 0s 110us/step - loss: 0.9889 - acc: 0.5085\n",
      "Epoch 24/41\n",
      "118/118 [==============================] - 0s 111us/step - loss: 0.9892 - acc: 0.5254\n",
      "Epoch 25/41\n",
      "118/118 [==============================] - 0s 120us/step - loss: 0.9712 - acc: 0.5339\n",
      "Epoch 26/41\n",
      "118/118 [==============================] - 0s 115us/step - loss: 0.9857 - acc: 0.5339\n",
      "Epoch 27/41\n",
      "118/118 [==============================] - 0s 124us/step - loss: 0.9754 - acc: 0.5169\n",
      "Epoch 28/41\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.9806 - acc: 0.500 - 0s 114us/step - loss: 0.9740 - acc: 0.5000\n",
      "Epoch 29/41\n",
      "118/118 [==============================] - 0s 121us/step - loss: 0.9663 - acc: 0.4661\n",
      "Epoch 30/41\n",
      "118/118 [==============================] - 0s 118us/step - loss: 0.9542 - acc: 0.5508\n",
      "Epoch 31/41\n",
      "118/118 [==============================] - 0s 122us/step - loss: 0.9502 - acc: 0.5763\n",
      "Epoch 32/41\n",
      "118/118 [==============================] - 0s 121us/step - loss: 0.9652 - acc: 0.5254\n",
      "Epoch 33/41\n",
      "118/118 [==============================] - 0s 118us/step - loss: 0.9607 - acc: 0.5678\n",
      "Epoch 34/41\n",
      "118/118 [==============================] - 0s 121us/step - loss: 0.9650 - acc: 0.5254\n",
      "Epoch 35/41\n",
      "118/118 [==============================] - 0s 114us/step - loss: 0.9509 - acc: 0.5254\n",
      "Epoch 36/41\n",
      "118/118 [==============================] - 0s 132us/step - loss: 0.9400 - acc: 0.5932\n",
      "Epoch 37/41\n",
      "118/118 [==============================] - 0s 155us/step - loss: 0.9391 - acc: 0.6102\n",
      "Epoch 38/41\n",
      "118/118 [==============================] - 0s 127us/step - loss: 0.9207 - acc: 0.6186\n",
      "Epoch 39/41\n",
      "118/118 [==============================] - 0s 125us/step - loss: 0.9163 - acc: 0.6441\n",
      "Epoch 40/41\n",
      "118/118 [==============================] - 0s 116us/step - loss: 0.9121 - acc: 0.6441\n",
      "Epoch 41/41\n",
      "118/118 [==============================] - 0s 135us/step - loss: 0.9086 - acc: 0.6441\n",
      "118/118 [==============================] - 0s 823us/step\n",
      "\n",
      "acc: 67.80%\n",
      "Testing score for Neural Network :  0.816666666667\n",
      "Epoch 1/46\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 1.1225 - acc: 0.2712\n",
      "Epoch 2/46\n",
      "118/118 [==============================] - 0s 116us/step - loss: 1.1067 - acc: 0.3305\n",
      "Epoch 3/46\n",
      "118/118 [==============================] - 0s 223us/step - loss: 1.1196 - acc: 0.2966\n",
      "Epoch 4/46\n",
      "118/118 [==============================] - 0s 254us/step - loss: 1.0862 - acc: 0.3898\n",
      "Epoch 5/46\n",
      "118/118 [==============================] - 0s 195us/step - loss: 1.0832 - acc: 0.3814\n",
      "Epoch 6/46\n",
      "118/118 [==============================] - 0s 233us/step - loss: 1.0830 - acc: 0.3983\n",
      "Epoch 7/46\n",
      "118/118 [==============================] - 0s 196us/step - loss: 1.0666 - acc: 0.4237\n",
      "Epoch 8/46\n",
      "118/118 [==============================] - 0s 241us/step - loss: 1.0663 - acc: 0.4322\n",
      "Epoch 9/46\n",
      "118/118 [==============================] - 0s 165us/step - loss: 1.0602 - acc: 0.4322\n",
      "Epoch 10/46\n",
      "118/118 [==============================] - 0s 172us/step - loss: 1.0466 - acc: 0.5678\n",
      "Epoch 11/46\n",
      "118/118 [==============================] - 0s 145us/step - loss: 1.0592 - acc: 0.4492\n",
      "Epoch 12/46\n",
      "118/118 [==============================] - 0s 139us/step - loss: 1.0494 - acc: 0.4407\n",
      "Epoch 13/46\n",
      "118/118 [==============================] - 0s 149us/step - loss: 1.0556 - acc: 0.3729\n",
      "Epoch 14/46\n",
      "118/118 [==============================] - 0s 140us/step - loss: 1.0531 - acc: 0.4831\n",
      "Epoch 15/46\n",
      "118/118 [==============================] - 0s 118us/step - loss: 1.0277 - acc: 0.5085\n",
      "Epoch 16/46\n",
      "118/118 [==============================] - 0s 114us/step - loss: 1.0271 - acc: 0.5254\n",
      "Epoch 17/46\n",
      "118/118 [==============================] - 0s 111us/step - loss: 1.0422 - acc: 0.4492\n",
      "Epoch 18/46\n",
      "118/118 [==============================] - 0s 111us/step - loss: 1.0326 - acc: 0.4831\n",
      "Epoch 19/46\n",
      "118/118 [==============================] - 0s 112us/step - loss: 1.0196 - acc: 0.5085\n",
      "Epoch 20/46\n",
      "118/118 [==============================] - 0s 115us/step - loss: 1.0067 - acc: 0.5254\n",
      "Epoch 21/46\n",
      "118/118 [==============================] - 0s 117us/step - loss: 1.0115 - acc: 0.4915\n",
      "Epoch 22/46\n",
      "118/118 [==============================] - 0s 120us/step - loss: 1.0043 - acc: 0.5424\n",
      "Epoch 23/46\n",
      "118/118 [==============================] - 0s 118us/step - loss: 1.0014 - acc: 0.5508\n",
      "Epoch 24/46\n",
      "118/118 [==============================] - 0s 121us/step - loss: 0.9880 - acc: 0.5000\n",
      "Epoch 25/46\n",
      "118/118 [==============================] - 0s 108us/step - loss: 1.0079 - acc: 0.5085\n",
      "Epoch 26/46\n",
      "118/118 [==============================] - 0s 120us/step - loss: 1.0016 - acc: 0.4746\n",
      "Epoch 27/46\n",
      "118/118 [==============================] - 0s 113us/step - loss: 0.9935 - acc: 0.5000\n",
      "Epoch 28/46\n",
      "118/118 [==============================] - 0s 115us/step - loss: 0.9800 - acc: 0.5424\n",
      "Epoch 29/46\n",
      "118/118 [==============================] - 0s 113us/step - loss: 0.9910 - acc: 0.5169\n",
      "Epoch 30/46\n",
      "118/118 [==============================] - 0s 118us/step - loss: 0.9750 - acc: 0.5424\n",
      "Epoch 31/46\n",
      "118/118 [==============================] - 0s 113us/step - loss: 0.9759 - acc: 0.5169\n",
      "Epoch 32/46\n",
      "118/118 [==============================] - 0s 112us/step - loss: 0.9794 - acc: 0.5169\n",
      "Epoch 33/46\n",
      "118/118 [==============================] - 0s 119us/step - loss: 0.9836 - acc: 0.5678\n",
      "Epoch 34/46\n",
      "118/118 [==============================] - 0s 360us/step - loss: 0.9475 - acc: 0.5678\n",
      "Epoch 35/46\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.9839 - acc: 0.400 - 0s 327us/step - loss: 0.9493 - acc: 0.5847\n",
      "Epoch 36/46\n",
      "118/118 [==============================] - 0s 220us/step - loss: 0.9527 - acc: 0.5593\n",
      "Epoch 37/46\n",
      "118/118 [==============================] - 0s 184us/step - loss: 0.9490 - acc: 0.5508\n",
      "Epoch 38/46\n",
      "118/118 [==============================] - 0s 152us/step - loss: 0.9477 - acc: 0.5508\n",
      "Epoch 39/46\n",
      "118/118 [==============================] - 0s 148us/step - loss: 0.9431 - acc: 0.5763\n",
      "Epoch 40/46\n",
      "118/118 [==============================] - 0s 141us/step - loss: 0.9386 - acc: 0.6017\n",
      "Epoch 41/46\n",
      "118/118 [==============================] - 0s 143us/step - loss: 0.9335 - acc: 0.5932\n",
      "Epoch 42/46\n",
      "118/118 [==============================] - 0s 122us/step - loss: 0.9266 - acc: 0.6017\n",
      "Epoch 43/46\n",
      "118/118 [==============================] - 0s 147us/step - loss: 0.9101 - acc: 0.6017\n",
      "Epoch 44/46\n",
      "118/118 [==============================] - 0s 112us/step - loss: 0.9004 - acc: 0.6441\n",
      "Epoch 45/46\n",
      "118/118 [==============================] - 0s 110us/step - loss: 0.8910 - acc: 0.6356\n",
      "Epoch 46/46\n",
      "118/118 [==============================] - 0s 115us/step - loss: 0.9090 - acc: 0.5932\n",
      "118/118 [==============================] - 0s 951us/step\n",
      "\n",
      "acc: 67.80%\n",
      "Testing score for Neural Network :  0.683333333333\n",
      "Epoch 1/51\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.1342 - acc: 0.2458\n",
      "Epoch 2/51\n",
      "118/118 [==============================] - 0s 135us/step - loss: 1.1290 - acc: 0.2881\n",
      "Epoch 3/51\n",
      "118/118 [==============================] - 0s 150us/step - loss: 1.1163 - acc: 0.3051\n",
      "Epoch 4/51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 0s 142us/step - loss: 1.0971 - acc: 0.3814\n",
      "Epoch 5/51\n",
      "118/118 [==============================] - 0s 121us/step - loss: 1.1049 - acc: 0.3220\n",
      "Epoch 6/51\n",
      "118/118 [==============================] - 0s 117us/step - loss: 1.0827 - acc: 0.3814\n",
      "Epoch 7/51\n",
      "118/118 [==============================] - 0s 116us/step - loss: 1.0666 - acc: 0.4492\n",
      "Epoch 8/51\n",
      "118/118 [==============================] - 0s 121us/step - loss: 1.0706 - acc: 0.4492\n",
      "Epoch 9/51\n",
      "118/118 [==============================] - 0s 114us/step - loss: 1.0671 - acc: 0.4153\n",
      "Epoch 10/51\n",
      "118/118 [==============================] - 0s 116us/step - loss: 1.0515 - acc: 0.4661\n",
      "Epoch 11/51\n",
      "118/118 [==============================] - 0s 116us/step - loss: 1.0432 - acc: 0.4915\n",
      "Epoch 12/51\n",
      "118/118 [==============================] - 0s 113us/step - loss: 1.0569 - acc: 0.5000\n",
      "Epoch 13/51\n",
      "118/118 [==============================] - 0s 116us/step - loss: 1.0454 - acc: 0.4661\n",
      "Epoch 14/51\n",
      "118/118 [==============================] - 0s 121us/step - loss: 1.0393 - acc: 0.4661\n",
      "Epoch 15/51\n",
      "118/118 [==============================] - 0s 284us/step - loss: 1.0376 - acc: 0.4831\n",
      "Epoch 16/51\n",
      "118/118 [==============================] - 0s 149us/step - loss: 1.0383 - acc: 0.4746\n",
      "Epoch 17/51\n",
      "118/118 [==============================] - 0s 129us/step - loss: 1.0318 - acc: 0.4661\n",
      "Epoch 18/51\n",
      "118/118 [==============================] - 0s 118us/step - loss: 1.0312 - acc: 0.4831\n",
      "Epoch 19/51\n",
      "118/118 [==============================] - 0s 123us/step - loss: 1.0246 - acc: 0.4915\n",
      "Epoch 20/51\n",
      "118/118 [==============================] - 0s 115us/step - loss: 0.9997 - acc: 0.5000\n",
      "Epoch 21/51\n",
      "118/118 [==============================] - 0s 121us/step - loss: 1.0136 - acc: 0.5085\n",
      "Epoch 22/51\n",
      "118/118 [==============================] - 0s 285us/step - loss: 1.0124 - acc: 0.5339\n",
      "Epoch 23/51\n",
      "118/118 [==============================] - 0s 243us/step - loss: 1.0173 - acc: 0.4915\n",
      "Epoch 24/51\n",
      "118/118 [==============================] - 0s 140us/step - loss: 0.9930 - acc: 0.5593\n",
      "Epoch 25/51\n",
      "118/118 [==============================] - 0s 120us/step - loss: 0.9844 - acc: 0.5254\n",
      "Epoch 26/51\n",
      "118/118 [==============================] - 0s 140us/step - loss: 0.9998 - acc: 0.5169\n",
      "Epoch 27/51\n",
      "118/118 [==============================] - 0s 122us/step - loss: 0.9941 - acc: 0.4915\n",
      "Epoch 28/51\n",
      "118/118 [==============================] - 0s 123us/step - loss: 0.9870 - acc: 0.5763\n",
      "Epoch 29/51\n",
      "118/118 [==============================] - 0s 129us/step - loss: 0.9831 - acc: 0.5508\n",
      "Epoch 30/51\n",
      "118/118 [==============================] - 0s 139us/step - loss: 0.9714 - acc: 0.5678\n",
      "Epoch 31/51\n",
      "118/118 [==============================] - 0s 155us/step - loss: 0.9780 - acc: 0.5678\n",
      "Epoch 32/51\n",
      "118/118 [==============================] - 0s 203us/step - loss: 0.9730 - acc: 0.5593\n",
      "Epoch 33/51\n",
      "118/118 [==============================] - 0s 285us/step - loss: 0.9738 - acc: 0.5593\n",
      "Epoch 34/51\n",
      "118/118 [==============================] - 0s 321us/step - loss: 0.9417 - acc: 0.6271\n",
      "Epoch 35/51\n",
      "118/118 [==============================] - 0s 248us/step - loss: 0.9641 - acc: 0.5339\n",
      "Epoch 36/51\n",
      "118/118 [==============================] - 0s 252us/step - loss: 0.9439 - acc: 0.6102\n",
      "Epoch 37/51\n",
      "118/118 [==============================] - 0s 198us/step - loss: 0.9467 - acc: 0.5932\n",
      "Epoch 38/51\n",
      "118/118 [==============================] - 0s 170us/step - loss: 0.9493 - acc: 0.5932\n",
      "Epoch 39/51\n",
      "118/118 [==============================] - 0s 156us/step - loss: 0.9181 - acc: 0.5847\n",
      "Epoch 40/51\n",
      "118/118 [==============================] - 0s 126us/step - loss: 0.9307 - acc: 0.6356\n",
      "Epoch 41/51\n",
      "118/118 [==============================] - 0s 119us/step - loss: 0.9177 - acc: 0.6017\n",
      "Epoch 42/51\n",
      "118/118 [==============================] - 0s 115us/step - loss: 0.9229 - acc: 0.5424\n",
      "Epoch 43/51\n",
      "118/118 [==============================] - 0s 117us/step - loss: 0.9183 - acc: 0.6271\n",
      "Epoch 44/51\n",
      "118/118 [==============================] - 0s 132us/step - loss: 0.9184 - acc: 0.6356\n",
      "Epoch 45/51\n",
      "118/118 [==============================] - 0s 144us/step - loss: 0.8899 - acc: 0.6949\n",
      "Epoch 46/51\n",
      "118/118 [==============================] - 0s 368us/step - loss: 0.8903 - acc: 0.7034\n",
      "Epoch 47/51\n",
      "118/118 [==============================] - 0s 333us/step - loss: 0.8908 - acc: 0.6949\n",
      "Epoch 48/51\n",
      "118/118 [==============================] - 0s 282us/step - loss: 0.8920 - acc: 0.6441\n",
      "Epoch 49/51\n",
      "118/118 [==============================] - 0s 395us/step - loss: 0.8791 - acc: 0.7119\n",
      "Epoch 50/51\n",
      "118/118 [==============================] - 0s 261us/step - loss: 0.8722 - acc: 0.7034\n",
      "Epoch 51/51\n",
      "118/118 [==============================] - 0s 219us/step - loss: 0.8453 - acc: 0.7119\n",
      "118/118 [==============================] - 0s 2ms/step\n",
      "\n",
      "acc: 78.81%\n",
      "Testing score for Neural Network :  0.783333333333\n",
      "Epoch 1/56\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.0981 - acc: 0.3220\n",
      "Epoch 2/56\n",
      "118/118 [==============================] - 0s 607us/step - loss: 1.0937 - acc: 0.3644\n",
      "Epoch 3/56\n",
      "118/118 [==============================] - 0s 408us/step - loss: 1.0886 - acc: 0.3814\n",
      "Epoch 4/56\n",
      "118/118 [==============================] - 0s 318us/step - loss: 1.0709 - acc: 0.4153\n",
      "Epoch 5/56\n",
      "118/118 [==============================] - ETA: 0s - loss: 1.0198 - acc: 0.400 - 0s 267us/step - loss: 1.0717 - acc: 0.4492\n",
      "Epoch 6/56\n",
      "118/118 [==============================] - 0s 271us/step - loss: 1.0639 - acc: 0.4492\n",
      "Epoch 7/56\n",
      "118/118 [==============================] - 0s 212us/step - loss: 1.0649 - acc: 0.4746\n",
      "Epoch 8/56\n",
      "118/118 [==============================] - 0s 159us/step - loss: 1.0687 - acc: 0.4661\n",
      "Epoch 9/56\n",
      "118/118 [==============================] - 0s 144us/step - loss: 1.0658 - acc: 0.4237\n",
      "Epoch 10/56\n",
      "118/118 [==============================] - 0s 153us/step - loss: 1.0765 - acc: 0.4153\n",
      "Epoch 11/56\n",
      "118/118 [==============================] - 0s 425us/step - loss: 1.0731 - acc: 0.4153\n",
      "Epoch 12/56\n",
      "118/118 [==============================] - 0s 424us/step - loss: 1.0499 - acc: 0.4661\n",
      "Epoch 13/56\n",
      "118/118 [==============================] - 0s 287us/step - loss: 1.0437 - acc: 0.4661\n",
      "Epoch 14/56\n",
      "118/118 [==============================] - 0s 289us/step - loss: 1.0338 - acc: 0.4661\n",
      "Epoch 15/56\n",
      "118/118 [==============================] - 0s 269us/step - loss: 1.0318 - acc: 0.4407\n",
      "Epoch 16/56\n",
      "118/118 [==============================] - 0s 249us/step - loss: 1.0400 - acc: 0.4407\n",
      "Epoch 17/56\n",
      "118/118 [==============================] - 0s 220us/step - loss: 1.0324 - acc: 0.4492\n",
      "Epoch 18/56\n",
      "118/118 [==============================] - 0s 196us/step - loss: 1.0316 - acc: 0.4492\n",
      "Epoch 19/56\n",
      "118/118 [==============================] - 0s 266us/step - loss: 1.0360 - acc: 0.4576\n",
      "Epoch 20/56\n",
      "118/118 [==============================] - 0s 222us/step - loss: 1.0265 - acc: 0.4576\n",
      "Epoch 21/56\n",
      "118/118 [==============================] - 0s 311us/step - loss: 1.0208 - acc: 0.4576\n",
      "Epoch 22/56\n",
      "118/118 [==============================] - 0s 276us/step - loss: 1.0145 - acc: 0.4831\n",
      "Epoch 23/56\n",
      "118/118 [==============================] - 0s 297us/step - loss: 0.9995 - acc: 0.4746\n",
      "Epoch 24/56\n",
      "118/118 [==============================] - 0s 288us/step - loss: 0.9980 - acc: 0.5000\n",
      "Epoch 25/56\n",
      "118/118 [==============================] - 0s 268us/step - loss: 1.0053 - acc: 0.4661\n",
      "Epoch 26/56\n",
      "118/118 [==============================] - 0s 258us/step - loss: 0.9969 - acc: 0.4407\n",
      "Epoch 27/56\n",
      "118/118 [==============================] - 0s 259us/step - loss: 0.9914 - acc: 0.5254\n",
      "Epoch 28/56\n",
      "118/118 [==============================] - 0s 274us/step - loss: 0.9980 - acc: 0.5085\n",
      "Epoch 29/56\n",
      "118/118 [==============================] - 0s 256us/step - loss: 0.9863 - acc: 0.4831\n",
      "Epoch 30/56\n",
      "118/118 [==============================] - 0s 244us/step - loss: 0.9842 - acc: 0.4831\n",
      "Epoch 31/56\n",
      "118/118 [==============================] - 0s 202us/step - loss: 0.9815 - acc: 0.4746\n",
      "Epoch 32/56\n",
      "118/118 [==============================] - 0s 235us/step - loss: 0.9607 - acc: 0.5000\n",
      "Epoch 33/56\n",
      "118/118 [==============================] - 0s 258us/step - loss: 0.9585 - acc: 0.5085\n",
      "Epoch 34/56\n",
      "118/118 [==============================] - 0s 242us/step - loss: 0.9599 - acc: 0.5254\n",
      "Epoch 35/56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 0s 238us/step - loss: 0.9600 - acc: 0.5254\n",
      "Epoch 36/56\n",
      "118/118 [==============================] - 0s 377us/step - loss: 0.9523 - acc: 0.5424\n",
      "Epoch 37/56\n",
      "118/118 [==============================] - 0s 403us/step - loss: 0.9457 - acc: 0.5169\n",
      "Epoch 38/56\n",
      "118/118 [==============================] - 0s 286us/step - loss: 0.9368 - acc: 0.5424\n",
      "Epoch 39/56\n",
      "118/118 [==============================] - 0s 378us/step - loss: 0.9320 - acc: 0.5424\n",
      "Epoch 40/56\n",
      "118/118 [==============================] - 0s 375us/step - loss: 0.9281 - acc: 0.5508\n",
      "Epoch 41/56\n",
      "118/118 [==============================] - 0s 298us/step - loss: 0.9199 - acc: 0.6186\n",
      "Epoch 42/56\n",
      "118/118 [==============================] - 0s 271us/step - loss: 0.9187 - acc: 0.6017\n",
      "Epoch 43/56\n",
      "118/118 [==============================] - 0s 275us/step - loss: 0.8892 - acc: 0.6780\n",
      "Epoch 44/56\n",
      "118/118 [==============================] - 0s 276us/step - loss: 0.8834 - acc: 0.7119\n",
      "Epoch 45/56\n",
      "118/118 [==============================] - 0s 251us/step - loss: 0.8837 - acc: 0.6780\n",
      "Epoch 46/56\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.8896 - acc: 0.800 - 0s 273us/step - loss: 0.8710 - acc: 0.7203\n",
      "Epoch 47/56\n",
      "118/118 [==============================] - 0s 225us/step - loss: 0.8807 - acc: 0.7119\n",
      "Epoch 48/56\n",
      "118/118 [==============================] - 0s 187us/step - loss: 0.8790 - acc: 0.6780\n",
      "Epoch 49/56\n",
      "118/118 [==============================] - 0s 266us/step - loss: 0.8617 - acc: 0.7288\n",
      "Epoch 50/56\n",
      "118/118 [==============================] - 0s 262us/step - loss: 0.8598 - acc: 0.7542\n",
      "Epoch 51/56\n",
      "118/118 [==============================] - 0s 267us/step - loss: 0.8578 - acc: 0.7288\n",
      "Epoch 52/56\n",
      "118/118 [==============================] - 0s 250us/step - loss: 0.8470 - acc: 0.7712\n",
      "Epoch 53/56\n",
      "118/118 [==============================] - 0s 258us/step - loss: 0.8292 - acc: 0.8051\n",
      "Epoch 54/56\n",
      "118/118 [==============================] - 0s 214us/step - loss: 0.8297 - acc: 0.7373\n",
      "Epoch 55/56\n",
      "118/118 [==============================] - 0s 231us/step - loss: 0.8186 - acc: 0.7712\n",
      "Epoch 56/56\n",
      "118/118 [==============================] - 0s 166us/step - loss: 0.8191 - acc: 0.8136\n",
      "118/118 [==============================] - 0s 2ms/step\n",
      "\n",
      "acc: 84.75%\n",
      "Testing score for Neural Network :  0.9\n",
      "Epoch 1/61\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 1.1130 - acc: 0.3559\n",
      "Epoch 2/61\n",
      "118/118 [==============================] - 0s 324us/step - loss: 1.1032 - acc: 0.3559\n",
      "Epoch 3/61\n",
      "118/118 [==============================] - 0s 333us/step - loss: 1.0852 - acc: 0.4407\n",
      "Epoch 4/61\n",
      "118/118 [==============================] - 0s 307us/step - loss: 1.0911 - acc: 0.4068\n",
      "Epoch 5/61\n",
      "118/118 [==============================] - 0s 365us/step - loss: 1.0862 - acc: 0.3729\n",
      "Epoch 6/61\n",
      "118/118 [==============================] - 0s 346us/step - loss: 1.0719 - acc: 0.4576\n",
      "Epoch 7/61\n",
      "118/118 [==============================] - 0s 269us/step - loss: 1.0622 - acc: 0.3983\n",
      "Epoch 8/61\n",
      "118/118 [==============================] - 0s 293us/step - loss: 1.0736 - acc: 0.4492\n",
      "Epoch 9/61\n",
      "118/118 [==============================] - 0s 319us/step - loss: 1.0667 - acc: 0.4576\n",
      "Epoch 10/61\n",
      "118/118 [==============================] - 0s 313us/step - loss: 1.0459 - acc: 0.4831\n",
      "Epoch 11/61\n",
      "118/118 [==============================] - 0s 301us/step - loss: 1.0478 - acc: 0.4746\n",
      "Epoch 12/61\n",
      "118/118 [==============================] - 0s 317us/step - loss: 1.0549 - acc: 0.4237\n",
      "Epoch 13/61\n",
      "118/118 [==============================] - 0s 315us/step - loss: 1.0454 - acc: 0.4237\n",
      "Epoch 14/61\n",
      "118/118 [==============================] - 0s 312us/step - loss: 1.0352 - acc: 0.4237\n",
      "Epoch 15/61\n",
      "118/118 [==============================] - 0s 286us/step - loss: 1.0396 - acc: 0.4746\n",
      "Epoch 16/61\n",
      "118/118 [==============================] - 0s 150us/step - loss: 1.0440 - acc: 0.4407\n",
      "Epoch 17/61\n",
      "118/118 [==============================] - 0s 148us/step - loss: 1.0199 - acc: 0.5085\n",
      "Epoch 18/61\n",
      "118/118 [==============================] - 0s 223us/step - loss: 1.0257 - acc: 0.4492\n",
      "Epoch 19/61\n",
      "118/118 [==============================] - 0s 424us/step - loss: 1.0259 - acc: 0.4915\n",
      "Epoch 20/61\n",
      "118/118 [==============================] - 0s 428us/step - loss: 1.0224 - acc: 0.4746\n",
      "Epoch 21/61\n",
      "118/118 [==============================] - 0s 432us/step - loss: 1.0132 - acc: 0.4576\n",
      "Epoch 22/61\n",
      "118/118 [==============================] - 0s 388us/step - loss: 0.9912 - acc: 0.4915\n",
      "Epoch 23/61\n",
      "118/118 [==============================] - 0s 302us/step - loss: 1.0025 - acc: 0.4915\n",
      "Epoch 24/61\n",
      "118/118 [==============================] - 0s 309us/step - loss: 0.9882 - acc: 0.4831\n",
      "Epoch 25/61\n",
      "118/118 [==============================] - 0s 296us/step - loss: 0.9843 - acc: 0.5169\n",
      "Epoch 26/61\n",
      "118/118 [==============================] - 0s 336us/step - loss: 0.9712 - acc: 0.5085\n",
      "Epoch 27/61\n",
      "118/118 [==============================] - 0s 287us/step - loss: 0.9811 - acc: 0.4746\n",
      "Epoch 28/61\n",
      "118/118 [==============================] - 0s 301us/step - loss: 0.9754 - acc: 0.4746\n",
      "Epoch 29/61\n",
      "118/118 [==============================] - 0s 270us/step - loss: 0.9670 - acc: 0.5339\n",
      "Epoch 30/61\n",
      "118/118 [==============================] - 0s 276us/step - loss: 0.9821 - acc: 0.4915\n",
      "Epoch 31/61\n",
      "118/118 [==============================] - 0s 258us/step - loss: 0.9680 - acc: 0.5000\n",
      "Epoch 32/61\n",
      "118/118 [==============================] - 0s 197us/step - loss: 0.9667 - acc: 0.5424\n",
      "Epoch 33/61\n",
      "118/118 [==============================] - 0s 231us/step - loss: 0.9508 - acc: 0.5254\n",
      "Epoch 34/61\n",
      "118/118 [==============================] - 0s 264us/step - loss: 0.9491 - acc: 0.5424\n",
      "Epoch 35/61\n",
      "118/118 [==============================] - 0s 248us/step - loss: 0.9415 - acc: 0.5593\n",
      "Epoch 36/61\n",
      "118/118 [==============================] - 0s 216us/step - loss: 0.9418 - acc: 0.5339\n",
      "Epoch 37/61\n",
      "118/118 [==============================] - 0s 260us/step - loss: 0.9209 - acc: 0.6186\n",
      "Epoch 38/61\n",
      "118/118 [==============================] - 0s 317us/step - loss: 0.9250 - acc: 0.5847\n",
      "Epoch 39/61\n",
      "118/118 [==============================] - 0s 383us/step - loss: 0.9155 - acc: 0.5932\n",
      "Epoch 40/61\n",
      "118/118 [==============================] - 0s 314us/step - loss: 0.9202 - acc: 0.5847\n",
      "Epoch 41/61\n",
      "118/118 [==============================] - 0s 286us/step - loss: 0.9031 - acc: 0.6102\n",
      "Epoch 42/61\n",
      "118/118 [==============================] - 0s 188us/step - loss: 0.9000 - acc: 0.6356\n",
      "Epoch 43/61\n",
      "118/118 [==============================] - 0s 221us/step - loss: 0.8814 - acc: 0.6102\n",
      "Epoch 44/61\n",
      "118/118 [==============================] - 0s 164us/step - loss: 0.8917 - acc: 0.6271\n",
      "Epoch 45/61\n",
      "118/118 [==============================] - 0s 190us/step - loss: 0.8677 - acc: 0.6780\n",
      "Epoch 46/61\n",
      "118/118 [==============================] - 0s 193us/step - loss: 0.8785 - acc: 0.6525\n",
      "Epoch 47/61\n",
      "118/118 [==============================] - 0s 204us/step - loss: 0.8572 - acc: 0.6864\n",
      "Epoch 48/61\n",
      "118/118 [==============================] - 0s 198us/step - loss: 0.8696 - acc: 0.6610\n",
      "Epoch 49/61\n",
      "118/118 [==============================] - 0s 239us/step - loss: 0.8547 - acc: 0.7203\n",
      "Epoch 50/61\n",
      "118/118 [==============================] - 0s 254us/step - loss: 0.8484 - acc: 0.7203\n",
      "Epoch 51/61\n",
      "118/118 [==============================] - 0s 223us/step - loss: 0.8374 - acc: 0.7203\n",
      "Epoch 52/61\n",
      "118/118 [==============================] - 0s 170us/step - loss: 0.8332 - acc: 0.7288\n",
      "Epoch 53/61\n",
      "118/118 [==============================] - 0s 247us/step - loss: 0.8330 - acc: 0.7627\n",
      "Epoch 54/61\n",
      "118/118 [==============================] - 0s 301us/step - loss: 0.8210 - acc: 0.7119\n",
      "Epoch 55/61\n",
      "118/118 [==============================] - 0s 277us/step - loss: 0.8122 - acc: 0.7458\n",
      "Epoch 56/61\n",
      "118/118 [==============================] - 0s 331us/step - loss: 0.7946 - acc: 0.8136\n",
      "Epoch 57/61\n",
      "118/118 [==============================] - 0s 350us/step - loss: 0.7990 - acc: 0.7881\n",
      "Epoch 58/61\n",
      "118/118 [==============================] - 0s 242us/step - loss: 0.7794 - acc: 0.8305\n",
      "Epoch 59/61\n",
      "118/118 [==============================] - 0s 271us/step - loss: 0.7896 - acc: 0.7627\n",
      "Epoch 60/61\n",
      "118/118 [==============================] - 0s 209us/step - loss: 0.7870 - acc: 0.7966\n",
      "Epoch 61/61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 0s 178us/step - loss: 0.7423 - acc: 0.8390\n",
      "118/118 [==============================] - 0s 2ms/step\n",
      "\n",
      "acc: 88.14%\n",
      "Testing score for Neural Network :  1.0\n",
      "Epoch 1/66\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 1.1409 - acc: 0.2288\n",
      "Epoch 2/66\n",
      "118/118 [==============================] - 0s 298us/step - loss: 1.1164 - acc: 0.2966\n",
      "Epoch 3/66\n",
      "118/118 [==============================] - 0s 235us/step - loss: 1.0992 - acc: 0.3729\n",
      "Epoch 4/66\n",
      "118/118 [==============================] - 0s 309us/step - loss: 1.1120 - acc: 0.2712\n",
      "Epoch 5/66\n",
      "118/118 [==============================] - 0s 282us/step - loss: 1.0971 - acc: 0.3136\n",
      "Epoch 6/66\n",
      "118/118 [==============================] - 0s 277us/step - loss: 1.0859 - acc: 0.3475\n",
      "Epoch 7/66\n",
      "118/118 [==============================] - 0s 285us/step - loss: 1.0802 - acc: 0.4068\n",
      "Epoch 8/66\n",
      "118/118 [==============================] - 0s 277us/step - loss: 1.0787 - acc: 0.3559\n",
      "Epoch 9/66\n",
      "118/118 [==============================] - 0s 421us/step - loss: 1.0831 - acc: 0.3814\n",
      "Epoch 10/66\n",
      "118/118 [==============================] - 0s 194us/step - loss: 1.0775 - acc: 0.3898\n",
      "Epoch 11/66\n",
      "118/118 [==============================] - 0s 243us/step - loss: 1.0725 - acc: 0.3983\n",
      "Epoch 12/66\n",
      "118/118 [==============================] - 0s 263us/step - loss: 1.0664 - acc: 0.4237\n",
      "Epoch 13/66\n",
      "118/118 [==============================] - 0s 256us/step - loss: 1.0568 - acc: 0.4492\n",
      "Epoch 14/66\n",
      "118/118 [==============================] - 0s 276us/step - loss: 1.0597 - acc: 0.4237\n",
      "Epoch 15/66\n",
      "118/118 [==============================] - 0s 403us/step - loss: 1.0830 - acc: 0.3898\n",
      "Epoch 16/66\n",
      "118/118 [==============================] - 0s 299us/step - loss: 1.0626 - acc: 0.4322\n",
      "Epoch 17/66\n",
      "118/118 [==============================] - 0s 365us/step - loss: 1.0401 - acc: 0.4746\n",
      "Epoch 18/66\n",
      "118/118 [==============================] - 0s 395us/step - loss: 1.0432 - acc: 0.4492\n",
      "Epoch 19/66\n",
      "118/118 [==============================] - 0s 296us/step - loss: 1.0491 - acc: 0.4322\n",
      "Epoch 20/66\n",
      "118/118 [==============================] - 0s 284us/step - loss: 1.0605 - acc: 0.4153\n",
      "Epoch 21/66\n",
      "118/118 [==============================] - 0s 293us/step - loss: 1.0521 - acc: 0.4237\n",
      "Epoch 22/66\n",
      "118/118 [==============================] - 0s 329us/step - loss: 1.0415 - acc: 0.4322\n",
      "Epoch 23/66\n",
      "118/118 [==============================] - 0s 290us/step - loss: 1.0437 - acc: 0.4237\n",
      "Epoch 24/66\n",
      "118/118 [==============================] - 0s 280us/step - loss: 1.0202 - acc: 0.5169\n",
      "Epoch 25/66\n",
      "118/118 [==============================] - 0s 313us/step - loss: 1.0376 - acc: 0.4153\n",
      "Epoch 26/66\n",
      "118/118 [==============================] - 0s 307us/step - loss: 1.0285 - acc: 0.4661\n",
      "Epoch 27/66\n",
      "118/118 [==============================] - 0s 293us/step - loss: 1.0147 - acc: 0.4915\n",
      "Epoch 28/66\n",
      "118/118 [==============================] - 0s 197us/step - loss: 1.0260 - acc: 0.4322\n",
      "Epoch 29/66\n",
      "118/118 [==============================] - 0s 226us/step - loss: 1.0229 - acc: 0.4576\n",
      "Epoch 30/66\n",
      "118/118 [==============================] - 0s 261us/step - loss: 1.0228 - acc: 0.5000\n",
      "Epoch 31/66\n",
      "118/118 [==============================] - 0s 209us/step - loss: 1.0208 - acc: 0.4831\n",
      "Epoch 32/66\n",
      "118/118 [==============================] - ETA: 0s - loss: 1.0463 - acc: 0.400 - 0s 139us/step - loss: 1.0246 - acc: 0.4831\n",
      "Epoch 33/66\n",
      "118/118 [==============================] - 0s 128us/step - loss: 1.0100 - acc: 0.4492\n",
      "Epoch 34/66\n",
      "118/118 [==============================] - 0s 128us/step - loss: 1.0114 - acc: 0.4661\n",
      "Epoch 35/66\n",
      "118/118 [==============================] - 0s 126us/step - loss: 0.9940 - acc: 0.4746\n",
      "Epoch 36/66\n",
      "118/118 [==============================] - 0s 186us/step - loss: 0.9872 - acc: 0.4407\n",
      "Epoch 37/66\n",
      "118/118 [==============================] - 0s 137us/step - loss: 0.9971 - acc: 0.4492\n",
      "Epoch 38/66\n",
      "118/118 [==============================] - 0s 136us/step - loss: 1.0037 - acc: 0.4915\n",
      "Epoch 39/66\n",
      "118/118 [==============================] - 0s 125us/step - loss: 0.9920 - acc: 0.5085\n",
      "Epoch 40/66\n",
      "118/118 [==============================] - 0s 153us/step - loss: 0.9745 - acc: 0.5424\n",
      "Epoch 41/66\n",
      "118/118 [==============================] - 0s 181us/step - loss: 0.9805 - acc: 0.5000\n",
      "Epoch 42/66\n",
      "118/118 [==============================] - 0s 144us/step - loss: 0.9656 - acc: 0.5085\n",
      "Epoch 43/66\n",
      "118/118 [==============================] - 0s 132us/step - loss: 0.9644 - acc: 0.5169\n",
      "Epoch 44/66\n",
      "118/118 [==============================] - 0s 125us/step - loss: 0.9782 - acc: 0.4831\n",
      "Epoch 45/66\n",
      "118/118 [==============================] - 0s 127us/step - loss: 0.9488 - acc: 0.5508\n",
      "Epoch 46/66\n",
      "118/118 [==============================] - 0s 133us/step - loss: 0.9585 - acc: 0.5000\n",
      "Epoch 47/66\n",
      "118/118 [==============================] - 0s 132us/step - loss: 0.9603 - acc: 0.5339\n",
      "Epoch 48/66\n",
      "118/118 [==============================] - 0s 114us/step - loss: 0.9538 - acc: 0.5254\n",
      "Epoch 49/66\n",
      "118/118 [==============================] - 0s 140us/step - loss: 0.9322 - acc: 0.5847\n",
      "Epoch 50/66\n",
      "118/118 [==============================] - 0s 143us/step - loss: 0.9473 - acc: 0.5424\n",
      "Epoch 51/66\n",
      "118/118 [==============================] - 0s 128us/step - loss: 0.9459 - acc: 0.5932\n",
      "Epoch 52/66\n",
      "118/118 [==============================] - 0s 127us/step - loss: 0.9356 - acc: 0.5763\n",
      "Epoch 53/66\n",
      "118/118 [==============================] - 0s 137us/step - loss: 0.9209 - acc: 0.6102\n",
      "Epoch 54/66\n",
      "118/118 [==============================] - 0s 116us/step - loss: 0.9118 - acc: 0.6102\n",
      "Epoch 55/66\n",
      "118/118 [==============================] - 0s 127us/step - loss: 0.9034 - acc: 0.6610\n",
      "Epoch 56/66\n",
      "118/118 [==============================] - 0s 123us/step - loss: 0.9056 - acc: 0.5847\n",
      "Epoch 57/66\n",
      "118/118 [==============================] - 0s 122us/step - loss: 0.8911 - acc: 0.6695\n",
      "Epoch 58/66\n",
      "118/118 [==============================] - 0s 122us/step - loss: 0.8971 - acc: 0.5763\n",
      "Epoch 59/66\n",
      "118/118 [==============================] - 0s 119us/step - loss: 0.8828 - acc: 0.6356\n",
      "Epoch 60/66\n",
      "118/118 [==============================] - 0s 114us/step - loss: 0.8831 - acc: 0.6780\n",
      "Epoch 61/66\n",
      "118/118 [==============================] - 0s 124us/step - loss: 0.8798 - acc: 0.6864\n",
      "Epoch 62/66\n",
      "118/118 [==============================] - 0s 121us/step - loss: 0.8684 - acc: 0.7119\n",
      "Epoch 63/66\n",
      "118/118 [==============================] - 0s 124us/step - loss: 0.8549 - acc: 0.7458\n",
      "Epoch 64/66\n",
      "118/118 [==============================] - 0s 123us/step - loss: 0.8534 - acc: 0.7034\n",
      "Epoch 65/66\n",
      "118/118 [==============================] - 0s 143us/step - loss: 0.8463 - acc: 0.7034\n",
      "Epoch 66/66\n",
      "118/118 [==============================] - 0s 172us/step - loss: 0.8328 - acc: 0.7627\n",
      "118/118 [==============================] - 0s 2ms/step\n",
      "\n",
      "acc: 79.66%\n",
      "Testing score for Neural Network :  0.833333333333\n",
      "Epoch 1/71\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 1.0736 - acc: 0.4576\n",
      "Epoch 2/71\n",
      "118/118 [==============================] - 0s 120us/step - loss: 1.0423 - acc: 0.4661\n",
      "Epoch 3/71\n",
      "118/118 [==============================] - 0s 119us/step - loss: 1.0648 - acc: 0.4068\n",
      "Epoch 4/71\n",
      "118/118 [==============================] - 0s 119us/step - loss: 1.0298 - acc: 0.5339\n",
      "Epoch 5/71\n",
      "118/118 [==============================] - 0s 120us/step - loss: 1.0305 - acc: 0.5000\n",
      "Epoch 6/71\n",
      "118/118 [==============================] - 0s 117us/step - loss: 1.0245 - acc: 0.5169\n",
      "Epoch 7/71\n",
      "118/118 [==============================] - 0s 115us/step - loss: 1.0439 - acc: 0.4407\n",
      "Epoch 8/71\n",
      "118/118 [==============================] - 0s 117us/step - loss: 1.0223 - acc: 0.4831\n",
      "Epoch 9/71\n",
      "118/118 [==============================] - 0s 114us/step - loss: 1.0127 - acc: 0.4322\n",
      "Epoch 10/71\n",
      "118/118 [==============================] - 0s 117us/step - loss: 1.0178 - acc: 0.4492\n",
      "Epoch 11/71\n",
      "118/118 [==============================] - 0s 119us/step - loss: 1.0228 - acc: 0.5169\n",
      "Epoch 12/71\n",
      "118/118 [==============================] - 0s 116us/step - loss: 0.9960 - acc: 0.5085\n",
      "Epoch 13/71\n",
      "118/118 [==============================] - 0s 134us/step - loss: 1.0020 - acc: 0.5254\n",
      "Epoch 14/71\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.9577 - acc: 0.500 - 0s 132us/step - loss: 1.0051 - acc: 0.4576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/71\n",
      "118/118 [==============================] - 0s 130us/step - loss: 0.9974 - acc: 0.4576\n",
      "Epoch 16/71\n",
      "118/118 [==============================] - 0s 117us/step - loss: 0.9961 - acc: 0.4915\n",
      "Epoch 17/71\n",
      "118/118 [==============================] - 0s 122us/step - loss: 0.9990 - acc: 0.4831\n",
      "Epoch 18/71\n",
      "118/118 [==============================] - 0s 122us/step - loss: 0.9853 - acc: 0.4831\n",
      "Epoch 19/71\n",
      "118/118 [==============================] - 0s 118us/step - loss: 0.9635 - acc: 0.4831\n",
      "Epoch 20/71\n",
      "118/118 [==============================] - 0s 119us/step - loss: 0.9713 - acc: 0.5254\n",
      "Epoch 21/71\n",
      "118/118 [==============================] - 0s 119us/step - loss: 0.9663 - acc: 0.5085\n",
      "Epoch 22/71\n",
      "118/118 [==============================] - 0s 118us/step - loss: 0.9601 - acc: 0.5254\n",
      "Epoch 23/71\n",
      "118/118 [==============================] - 0s 123us/step - loss: 0.9615 - acc: 0.5085\n",
      "Epoch 24/71\n",
      "118/118 [==============================] - 0s 120us/step - loss: 0.9452 - acc: 0.5593\n",
      "Epoch 25/71\n",
      "118/118 [==============================] - 0s 115us/step - loss: 0.9409 - acc: 0.5169\n",
      "Epoch 26/71\n",
      "118/118 [==============================] - 0s 114us/step - loss: 0.9199 - acc: 0.6356\n",
      "Epoch 27/71\n",
      "118/118 [==============================] - 0s 131us/step - loss: 0.9351 - acc: 0.5424\n",
      "Epoch 28/71\n",
      "118/118 [==============================] - 0s 119us/step - loss: 0.9270 - acc: 0.5847\n",
      "Epoch 29/71\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.8850 - acc: 0.600 - 0s 124us/step - loss: 0.9137 - acc: 0.6271\n",
      "Epoch 30/71\n",
      "118/118 [==============================] - 0s 132us/step - loss: 0.9132 - acc: 0.6356\n",
      "Epoch 31/71\n",
      "118/118 [==============================] - 0s 133us/step - loss: 0.9041 - acc: 0.6695\n",
      "Epoch 32/71\n",
      "118/118 [==============================] - 0s 131us/step - loss: 0.9071 - acc: 0.6610\n",
      "Epoch 33/71\n",
      "118/118 [==============================] - 0s 123us/step - loss: 0.8841 - acc: 0.6864\n",
      "Epoch 34/71\n",
      "118/118 [==============================] - 0s 119us/step - loss: 0.8919 - acc: 0.6949\n",
      "Epoch 35/71\n",
      "118/118 [==============================] - 0s 145us/step - loss: 0.8800 - acc: 0.6780\n",
      "Epoch 36/71\n",
      "118/118 [==============================] - 0s 124us/step - loss: 0.8707 - acc: 0.6441\n",
      "Epoch 37/71\n",
      "118/118 [==============================] - 0s 122us/step - loss: 0.8833 - acc: 0.7034\n",
      "Epoch 38/71\n",
      "118/118 [==============================] - 0s 128us/step - loss: 0.8686 - acc: 0.7119\n",
      "Epoch 39/71\n",
      "118/118 [==============================] - 0s 145us/step - loss: 0.8617 - acc: 0.6864\n",
      "Epoch 40/71\n",
      "118/118 [==============================] - 0s 271us/step - loss: 0.8529 - acc: 0.6864\n",
      "Epoch 41/71\n",
      "118/118 [==============================] - 0s 294us/step - loss: 0.8438 - acc: 0.7119\n",
      "Epoch 42/71\n",
      "118/118 [==============================] - 0s 267us/step - loss: 0.8398 - acc: 0.7373\n",
      "Epoch 43/71\n",
      "118/118 [==============================] - 0s 280us/step - loss: 0.8289 - acc: 0.7119\n",
      "Epoch 44/71\n",
      "118/118 [==============================] - 0s 274us/step - loss: 0.8296 - acc: 0.7542\n",
      "Epoch 45/71\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.8620 - acc: 0.700 - 0s 250us/step - loss: 0.8184 - acc: 0.7034\n",
      "Epoch 46/71\n",
      "118/118 [==============================] - 0s 243us/step - loss: 0.8044 - acc: 0.7712\n",
      "Epoch 47/71\n",
      "118/118 [==============================] - 0s 130us/step - loss: 0.8013 - acc: 0.7373\n",
      "Epoch 48/71\n",
      "118/118 [==============================] - 0s 122us/step - loss: 0.7981 - acc: 0.7542\n",
      "Epoch 49/71\n",
      "118/118 [==============================] - 0s 121us/step - loss: 0.8053 - acc: 0.7542\n",
      "Epoch 50/71\n",
      "118/118 [==============================] - 0s 114us/step - loss: 0.7838 - acc: 0.7627\n",
      "Epoch 51/71\n",
      "118/118 [==============================] - 0s 122us/step - loss: 0.7850 - acc: 0.7797\n",
      "Epoch 52/71\n",
      "118/118 [==============================] - 0s 128us/step - loss: 0.7676 - acc: 0.7458\n",
      "Epoch 53/71\n",
      "118/118 [==============================] - 0s 123us/step - loss: 0.7585 - acc: 0.7966\n",
      "Epoch 54/71\n",
      "118/118 [==============================] - 0s 125us/step - loss: 0.7560 - acc: 0.7627\n",
      "Epoch 55/71\n",
      "118/118 [==============================] - 0s 129us/step - loss: 0.7483 - acc: 0.7712\n",
      "Epoch 56/71\n",
      "118/118 [==============================] - 0s 122us/step - loss: 0.7639 - acc: 0.8136\n",
      "Epoch 57/71\n",
      "118/118 [==============================] - 0s 119us/step - loss: 0.7557 - acc: 0.8220\n",
      "Epoch 58/71\n",
      "118/118 [==============================] - 0s 137us/step - loss: 0.7286 - acc: 0.8390\n",
      "Epoch 59/71\n",
      "118/118 [==============================] - 0s 178us/step - loss: 0.7238 - acc: 0.8051\n",
      "Epoch 60/71\n",
      "118/118 [==============================] - 0s 291us/step - loss: 0.7264 - acc: 0.8644\n",
      "Epoch 61/71\n",
      "118/118 [==============================] - 0s 308us/step - loss: 0.7022 - acc: 0.8729\n",
      "Epoch 62/71\n",
      "118/118 [==============================] - 0s 247us/step - loss: 0.6945 - acc: 0.8136\n",
      "Epoch 63/71\n",
      "118/118 [==============================] - 0s 358us/step - loss: 0.6799 - acc: 0.8559\n",
      "Epoch 64/71\n",
      "118/118 [==============================] - 0s 323us/step - loss: 0.6755 - acc: 0.8305\n",
      "Epoch 65/71\n",
      "118/118 [==============================] - 0s 211us/step - loss: 0.6691 - acc: 0.8644\n",
      "Epoch 66/71\n",
      "118/118 [==============================] - 0s 252us/step - loss: 0.6797 - acc: 0.8559\n",
      "Epoch 67/71\n",
      "118/118 [==============================] - 0s 136us/step - loss: 0.6704 - acc: 0.8559\n",
      "Epoch 68/71\n",
      "118/118 [==============================] - 0s 128us/step - loss: 0.6732 - acc: 0.8220\n",
      "Epoch 69/71\n",
      "118/118 [==============================] - 0s 119us/step - loss: 0.6511 - acc: 0.8983\n",
      "Epoch 70/71\n",
      "118/118 [==============================] - 0s 136us/step - loss: 0.6520 - acc: 0.8644\n",
      "Epoch 71/71\n",
      "118/118 [==============================] - 0s 147us/step - loss: 0.6455 - acc: 0.8559\n",
      "118/118 [==============================] - 0s 2ms/step\n",
      "\n",
      "acc: 91.53%\n",
      "Testing score for Neural Network :  0.966666666667\n",
      "Epoch 1/76\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.1085 - acc: 0.2797\n",
      "Epoch 2/76\n",
      "118/118 [==============================] - 0s 230us/step - loss: 1.1046 - acc: 0.3390\n",
      "Epoch 3/76\n",
      "118/118 [==============================] - 0s 292us/step - loss: 1.0858 - acc: 0.4068\n",
      "Epoch 4/76\n",
      "118/118 [==============================] - 0s 322us/step - loss: 1.0749 - acc: 0.3983\n",
      "Epoch 5/76\n",
      "118/118 [==============================] - 0s 352us/step - loss: 1.0813 - acc: 0.4068\n",
      "Epoch 6/76\n",
      "118/118 [==============================] - 0s 374us/step - loss: 1.0623 - acc: 0.4407\n",
      "Epoch 7/76\n",
      "118/118 [==============================] - 0s 304us/step - loss: 1.0717 - acc: 0.4407\n",
      "Epoch 8/76\n",
      "118/118 [==============================] - 0s 189us/step - loss: 1.0578 - acc: 0.4915\n",
      "Epoch 9/76\n",
      "118/118 [==============================] - 0s 262us/step - loss: 1.0612 - acc: 0.4915\n",
      "Epoch 10/76\n",
      "118/118 [==============================] - 0s 235us/step - loss: 1.0541 - acc: 0.4407\n",
      "Epoch 11/76\n",
      "118/118 [==============================] - 0s 177us/step - loss: 1.0580 - acc: 0.4746\n",
      "Epoch 12/76\n",
      "118/118 [==============================] - 0s 265us/step - loss: 1.0420 - acc: 0.4746\n",
      "Epoch 13/76\n",
      "118/118 [==============================] - 0s 268us/step - loss: 1.0490 - acc: 0.4237\n",
      "Epoch 14/76\n",
      "118/118 [==============================] - 0s 256us/step - loss: 1.0358 - acc: 0.4492\n",
      "Epoch 15/76\n",
      "118/118 [==============================] - 0s 272us/step - loss: 1.0481 - acc: 0.4915\n",
      "Epoch 16/76\n",
      "118/118 [==============================] - 0s 214us/step - loss: 1.0348 - acc: 0.4746\n",
      "Epoch 17/76\n",
      "118/118 [==============================] - 0s 129us/step - loss: 1.0327 - acc: 0.4661\n",
      "Epoch 18/76\n",
      "118/118 [==============================] - 0s 134us/step - loss: 1.0278 - acc: 0.5169\n",
      "Epoch 19/76\n",
      "118/118 [==============================] - 0s 125us/step - loss: 1.0341 - acc: 0.4576\n",
      "Epoch 20/76\n",
      "118/118 [==============================] - 0s 117us/step - loss: 1.0076 - acc: 0.5508\n",
      "Epoch 21/76\n",
      "118/118 [==============================] - 0s 118us/step - loss: 1.0042 - acc: 0.4661\n",
      "Epoch 22/76\n",
      "118/118 [==============================] - 0s 117us/step - loss: 1.0149 - acc: 0.5169\n",
      "Epoch 23/76\n",
      "118/118 [==============================] - 0s 121us/step - loss: 1.0214 - acc: 0.4661\n",
      "Epoch 24/76\n",
      "118/118 [==============================] - 0s 119us/step - loss: 0.9887 - acc: 0.5593\n",
      "Epoch 25/76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 0s 132us/step - loss: 0.9906 - acc: 0.5085\n",
      "Epoch 26/76\n",
      "118/118 [==============================] - 0s 116us/step - loss: 0.9939 - acc: 0.5424\n",
      "Epoch 27/76\n",
      "118/118 [==============================] - 0s 118us/step - loss: 0.9926 - acc: 0.4915\n",
      "Epoch 28/76\n",
      "118/118 [==============================] - 0s 139us/step - loss: 0.9757 - acc: 0.5593\n",
      "Epoch 29/76\n",
      "118/118 [==============================] - 0s 216us/step - loss: 0.9900 - acc: 0.5932\n",
      "Epoch 30/76\n",
      "118/118 [==============================] - 0s 290us/step - loss: 0.9732 - acc: 0.5508\n",
      "Epoch 31/76\n",
      "118/118 [==============================] - 0s 330us/step - loss: 0.9527 - acc: 0.6102\n",
      "Epoch 32/76\n",
      "118/118 [==============================] - 0s 335us/step - loss: 0.9706 - acc: 0.5763\n",
      "Epoch 33/76\n",
      "118/118 [==============================] - 0s 292us/step - loss: 0.9711 - acc: 0.6102\n",
      "Epoch 34/76\n",
      "118/118 [==============================] - 0s 303us/step - loss: 0.9427 - acc: 0.6017\n",
      "Epoch 35/76\n",
      "118/118 [==============================] - 0s 300us/step - loss: 0.9455 - acc: 0.6441\n",
      "Epoch 36/76\n",
      "118/118 [==============================] - 0s 282us/step - loss: 0.9474 - acc: 0.5508\n",
      "Epoch 37/76\n",
      "118/118 [==============================] - 0s 263us/step - loss: 0.9446 - acc: 0.5932\n",
      "Epoch 38/76\n",
      "118/118 [==============================] - 0s 409us/step - loss: 0.9192 - acc: 0.6525\n",
      "Epoch 39/76\n",
      "118/118 [==============================] - 0s 338us/step - loss: 0.9195 - acc: 0.6610\n",
      "Epoch 40/76\n",
      "118/118 [==============================] - 0s 309us/step - loss: 0.9371 - acc: 0.6356\n",
      "Epoch 41/76\n",
      "118/118 [==============================] - 0s 357us/step - loss: 0.9124 - acc: 0.6441\n",
      "Epoch 42/76\n",
      "118/118 [==============================] - 0s 281us/step - loss: 0.9093 - acc: 0.6186\n",
      "Epoch 43/76\n",
      "118/118 [==============================] - 0s 305us/step - loss: 0.9106 - acc: 0.6102\n",
      "Epoch 44/76\n",
      "118/118 [==============================] - 0s 400us/step - loss: 0.9049 - acc: 0.6102\n",
      "Epoch 45/76\n",
      "118/118 [==============================] - 0s 368us/step - loss: 0.8824 - acc: 0.6949\n",
      "Epoch 46/76\n",
      "118/118 [==============================] - 0s 307us/step - loss: 0.8789 - acc: 0.6864\n",
      "Epoch 47/76\n",
      "118/118 [==============================] - 0s 295us/step - loss: 0.8842 - acc: 0.6949\n",
      "Epoch 48/76\n",
      "118/118 [==============================] - 0s 313us/step - loss: 0.8867 - acc: 0.6186\n",
      "Epoch 49/76\n",
      "118/118 [==============================] - 0s 285us/step - loss: 0.8616 - acc: 0.7203\n",
      "Epoch 50/76\n",
      "118/118 [==============================] - 0s 288us/step - loss: 0.8571 - acc: 0.7203\n",
      "Epoch 51/76\n",
      "118/118 [==============================] - 0s 290us/step - loss: 0.8520 - acc: 0.7627\n",
      "Epoch 52/76\n",
      "118/118 [==============================] - 0s 240us/step - loss: 0.8539 - acc: 0.7119\n",
      "Epoch 53/76\n",
      "118/118 [==============================] - 0s 312us/step - loss: 0.8350 - acc: 0.7458\n",
      "Epoch 54/76\n",
      "118/118 [==============================] - 0s 300us/step - loss: 0.8271 - acc: 0.7881\n",
      "Epoch 55/76\n",
      "118/118 [==============================] - 0s 354us/step - loss: 0.8176 - acc: 0.7627\n",
      "Epoch 56/76\n",
      "118/118 [==============================] - 0s 330us/step - loss: 0.8130 - acc: 0.7797\n",
      "Epoch 57/76\n",
      "118/118 [==============================] - 0s 405us/step - loss: 0.8138 - acc: 0.7627\n",
      "Epoch 58/76\n",
      "118/118 [==============================] - 0s 273us/step - loss: 0.7935 - acc: 0.7966\n",
      "Epoch 59/76\n",
      "118/118 [==============================] - 0s 293us/step - loss: 0.7921 - acc: 0.7627\n",
      "Epoch 60/76\n",
      "118/118 [==============================] - 0s 252us/step - loss: 0.8090 - acc: 0.7712\n",
      "Epoch 61/76\n",
      "118/118 [==============================] - 0s 202us/step - loss: 0.7724 - acc: 0.8220\n",
      "Epoch 62/76\n",
      "118/118 [==============================] - 0s 228us/step - loss: 0.7676 - acc: 0.8220\n",
      "Epoch 63/76\n",
      "118/118 [==============================] - 0s 236us/step - loss: 0.7599 - acc: 0.8051\n",
      "Epoch 64/76\n",
      "118/118 [==============================] - 0s 201us/step - loss: 0.7414 - acc: 0.8136\n",
      "Epoch 65/76\n",
      "118/118 [==============================] - 0s 206us/step - loss: 0.7477 - acc: 0.8644\n",
      "Epoch 66/76\n",
      "118/118 [==============================] - 0s 207us/step - loss: 0.7407 - acc: 0.8729\n",
      "Epoch 67/76\n",
      "118/118 [==============================] - 0s 203us/step - loss: 0.7103 - acc: 0.8559\n",
      "Epoch 68/76\n",
      "118/118 [==============================] - 0s 225us/step - loss: 0.7073 - acc: 0.8644\n",
      "Epoch 69/76\n",
      "118/118 [==============================] - 0s 172us/step - loss: 0.7209 - acc: 0.8390\n",
      "Epoch 70/76\n",
      "118/118 [==============================] - 0s 184us/step - loss: 0.7103 - acc: 0.8898\n",
      "Epoch 71/76\n",
      "118/118 [==============================] - 0s 131us/step - loss: 0.7018 - acc: 0.8729\n",
      "Epoch 72/76\n",
      "118/118 [==============================] - 0s 133us/step - loss: 0.7080 - acc: 0.8644\n",
      "Epoch 73/76\n",
      "118/118 [==============================] - 0s 137us/step - loss: 0.6933 - acc: 0.9153\n",
      "Epoch 74/76\n",
      "118/118 [==============================] - 0s 158us/step - loss: 0.6983 - acc: 0.8644\n",
      "Epoch 75/76\n",
      "118/118 [==============================] - 0s 246us/step - loss: 0.6629 - acc: 0.8898\n",
      "Epoch 76/76\n",
      "118/118 [==============================] - 0s 257us/step - loss: 0.6922 - acc: 0.8305\n",
      "118/118 [==============================] - 0s 2ms/step\n",
      "\n",
      "acc: 90.68%\n",
      "Testing score for Neural Network :  0.9\n",
      "Epoch 1/81\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 1.1075 - acc: 0.2288\n",
      "Epoch 2/81\n",
      "118/118 [==============================] - 0s 128us/step - loss: 1.0962 - acc: 0.3559\n",
      "Epoch 3/81\n",
      "118/118 [==============================] - 0s 116us/step - loss: 1.0845 - acc: 0.4746\n",
      "Epoch 4/81\n",
      "118/118 [==============================] - 0s 119us/step - loss: 1.0932 - acc: 0.4492\n",
      "Epoch 5/81\n",
      "118/118 [==============================] - 0s 114us/step - loss: 1.0753 - acc: 0.4576\n",
      "Epoch 6/81\n",
      "118/118 [==============================] - 0s 128us/step - loss: 1.0730 - acc: 0.4831\n",
      "Epoch 7/81\n",
      "118/118 [==============================] - 0s 220us/step - loss: 1.0587 - acc: 0.5000\n",
      "Epoch 8/81\n",
      "118/118 [==============================] - 0s 148us/step - loss: 1.0600 - acc: 0.4661\n",
      "Epoch 9/81\n",
      "118/118 [==============================] - 0s 152us/step - loss: 1.0648 - acc: 0.4492\n",
      "Epoch 10/81\n",
      "118/118 [==============================] - 0s 159us/step - loss: 1.0530 - acc: 0.4746\n",
      "Epoch 11/81\n",
      "118/118 [==============================] - 0s 193us/step - loss: 1.0440 - acc: 0.4576\n",
      "Epoch 12/81\n",
      "118/118 [==============================] - 0s 149us/step - loss: 1.0252 - acc: 0.4492\n",
      "Epoch 13/81\n",
      "118/118 [==============================] - 0s 137us/step - loss: 1.0294 - acc: 0.4492\n",
      "Epoch 14/81\n",
      "118/118 [==============================] - 0s 131us/step - loss: 1.0327 - acc: 0.4831\n",
      "Epoch 15/81\n",
      "118/118 [==============================] - 0s 143us/step - loss: 1.0496 - acc: 0.4661\n",
      "Epoch 16/81\n",
      "118/118 [==============================] - 0s 141us/step - loss: 1.0160 - acc: 0.4831\n",
      "Epoch 17/81\n",
      "118/118 [==============================] - 0s 156us/step - loss: 1.0187 - acc: 0.4492\n",
      "Epoch 18/81\n",
      "118/118 [==============================] - 0s 155us/step - loss: 1.0265 - acc: 0.5085\n",
      "Epoch 19/81\n",
      "118/118 [==============================] - 0s 224us/step - loss: 1.0276 - acc: 0.4915\n",
      "Epoch 20/81\n",
      "118/118 [==============================] - 0s 209us/step - loss: 1.0192 - acc: 0.5085\n",
      "Epoch 21/81\n",
      "118/118 [==============================] - 0s 166us/step - loss: 1.0006 - acc: 0.4915\n",
      "Epoch 22/81\n",
      "118/118 [==============================] - 0s 141us/step - loss: 1.0228 - acc: 0.5000\n",
      "Epoch 23/81\n",
      "118/118 [==============================] - 0s 143us/step - loss: 0.9992 - acc: 0.5254\n",
      "Epoch 24/81\n",
      "118/118 [==============================] - 0s 157us/step - loss: 0.9866 - acc: 0.5169\n",
      "Epoch 25/81\n",
      "118/118 [==============================] - 0s 166us/step - loss: 0.9896 - acc: 0.5424\n",
      "Epoch 26/81\n",
      "118/118 [==============================] - 0s 157us/step - loss: 0.9841 - acc: 0.5339\n",
      "Epoch 27/81\n",
      "118/118 [==============================] - 0s 151us/step - loss: 0.9761 - acc: 0.5169\n",
      "Epoch 28/81\n",
      "118/118 [==============================] - 0s 163us/step - loss: 0.9701 - acc: 0.5508\n",
      "Epoch 29/81\n",
      "118/118 [==============================] - 0s 230us/step - loss: 0.9846 - acc: 0.5169\n",
      "Epoch 30/81\n",
      "118/118 [==============================] - 0s 183us/step - loss: 0.9607 - acc: 0.5254\n",
      "Epoch 31/81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 0s 253us/step - loss: 0.9523 - acc: 0.5424\n",
      "Epoch 32/81\n",
      "118/118 [==============================] - 0s 261us/step - loss: 0.9479 - acc: 0.5508\n",
      "Epoch 33/81\n",
      "118/118 [==============================] - 0s 306us/step - loss: 0.9439 - acc: 0.5508\n",
      "Epoch 34/81\n",
      "118/118 [==============================] - 0s 152us/step - loss: 0.9461 - acc: 0.5508\n",
      "Epoch 35/81\n",
      "118/118 [==============================] - 0s 134us/step - loss: 0.9351 - acc: 0.5593\n",
      "Epoch 36/81\n",
      "118/118 [==============================] - 0s 148us/step - loss: 0.9505 - acc: 0.5763\n",
      "Epoch 37/81\n",
      "118/118 [==============================] - 0s 122us/step - loss: 0.9350 - acc: 0.5678\n",
      "Epoch 38/81\n",
      "118/118 [==============================] - 0s 128us/step - loss: 0.9196 - acc: 0.6271\n",
      "Epoch 39/81\n",
      "118/118 [==============================] - 0s 136us/step - loss: 0.9221 - acc: 0.6186\n",
      "Epoch 40/81\n",
      "118/118 [==============================] - 0s 129us/step - loss: 0.9077 - acc: 0.6525\n",
      "Epoch 41/81\n",
      "118/118 [==============================] - 0s 133us/step - loss: 0.9089 - acc: 0.6271\n",
      "Epoch 42/81\n",
      "118/118 [==============================] - 0s 129us/step - loss: 0.9010 - acc: 0.6441\n",
      "Epoch 43/81\n",
      "118/118 [==============================] - 0s 132us/step - loss: 0.8779 - acc: 0.6864\n",
      "Epoch 44/81\n",
      "118/118 [==============================] - 0s 129us/step - loss: 0.8719 - acc: 0.6864\n",
      "Epoch 45/81\n",
      "118/118 [==============================] - 0s 127us/step - loss: 0.8799 - acc: 0.6780\n",
      "Epoch 46/81\n",
      "118/118 [==============================] - 0s 127us/step - loss: 0.8596 - acc: 0.7203\n",
      "Epoch 47/81\n",
      "118/118 [==============================] - 0s 139us/step - loss: 0.8497 - acc: 0.7119\n",
      "Epoch 48/81\n",
      "118/118 [==============================] - 0s 131us/step - loss: 0.8395 - acc: 0.7797\n",
      "Epoch 49/81\n",
      "118/118 [==============================] - 0s 152us/step - loss: 0.8347 - acc: 0.7881\n",
      "Epoch 50/81\n",
      "118/118 [==============================] - 0s 132us/step - loss: 0.8216 - acc: 0.7881\n",
      "Epoch 51/81\n",
      "118/118 [==============================] - 0s 130us/step - loss: 0.8534 - acc: 0.7458\n",
      "Epoch 52/81\n",
      "118/118 [==============================] - 0s 126us/step - loss: 0.8341 - acc: 0.7203\n",
      "Epoch 53/81\n",
      "118/118 [==============================] - 0s 129us/step - loss: 0.8068 - acc: 0.7966\n",
      "Epoch 54/81\n",
      "118/118 [==============================] - 0s 168us/step - loss: 0.8094 - acc: 0.7881\n",
      "Epoch 55/81\n",
      "118/118 [==============================] - 0s 171us/step - loss: 0.7922 - acc: 0.7542\n",
      "Epoch 56/81\n",
      "118/118 [==============================] - 0s 158us/step - loss: 0.7668 - acc: 0.8051\n",
      "Epoch 57/81\n",
      "118/118 [==============================] - 0s 245us/step - loss: 0.7699 - acc: 0.8051\n",
      "Epoch 58/81\n",
      "118/118 [==============================] - 0s 170us/step - loss: 0.7839 - acc: 0.8051\n",
      "Epoch 59/81\n",
      "118/118 [==============================] - 0s 202us/step - loss: 0.7740 - acc: 0.7881\n",
      "Epoch 60/81\n",
      "118/118 [==============================] - 0s 212us/step - loss: 0.7555 - acc: 0.8559\n",
      "Epoch 61/81\n",
      "118/118 [==============================] - 0s 230us/step - loss: 0.7564 - acc: 0.8136\n",
      "Epoch 62/81\n",
      "118/118 [==============================] - 0s 392us/step - loss: 0.7352 - acc: 0.8559\n",
      "Epoch 63/81\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6782 - acc: 1.000 - 0s 387us/step - loss: 0.7455 - acc: 0.8390\n",
      "Epoch 64/81\n",
      "118/118 [==============================] - 0s 161us/step - loss: 0.7258 - acc: 0.8305\n",
      "Epoch 65/81\n",
      "118/118 [==============================] - 0s 980us/step - loss: 0.7136 - acc: 0.8390\n",
      "Epoch 66/81\n",
      "118/118 [==============================] - 0s 722us/step - loss: 0.7114 - acc: 0.8475\n",
      "Epoch 67/81\n",
      "118/118 [==============================] - 0s 309us/step - loss: 0.7015 - acc: 0.8559\n",
      "Epoch 68/81\n",
      "118/118 [==============================] - 0s 195us/step - loss: 0.6882 - acc: 0.8814\n",
      "Epoch 69/81\n",
      "118/118 [==============================] - 0s 148us/step - loss: 0.6837 - acc: 0.8220\n",
      "Epoch 70/81\n",
      "118/118 [==============================] - 0s 148us/step - loss: 0.6829 - acc: 0.8475\n",
      "Epoch 71/81\n",
      "118/118 [==============================] - 0s 223us/step - loss: 0.6850 - acc: 0.8559\n",
      "Epoch 72/81\n",
      "118/118 [==============================] - 0s 168us/step - loss: 0.6575 - acc: 0.9068\n",
      "Epoch 73/81\n",
      "118/118 [==============================] - 0s 161us/step - loss: 0.6501 - acc: 0.8729\n",
      "Epoch 74/81\n",
      "118/118 [==============================] - 0s 124us/step - loss: 0.6532 - acc: 0.8898\n",
      "Epoch 75/81\n",
      "118/118 [==============================] - 0s 142us/step - loss: 0.6467 - acc: 0.8644\n",
      "Epoch 76/81\n",
      "118/118 [==============================] - 0s 115us/step - loss: 0.6155 - acc: 0.8729\n",
      "Epoch 77/81\n",
      "118/118 [==============================] - 0s 122us/step - loss: 0.6370 - acc: 0.8475\n",
      "Epoch 78/81\n",
      "118/118 [==============================] - 0s 133us/step - loss: 0.6283 - acc: 0.8898\n",
      "Epoch 79/81\n",
      "118/118 [==============================] - 0s 135us/step - loss: 0.6208 - acc: 0.8983\n",
      "Epoch 80/81\n",
      "118/118 [==============================] - 0s 123us/step - loss: 0.5876 - acc: 0.8644\n",
      "Epoch 81/81\n",
      "118/118 [==============================] - 0s 127us/step - loss: 0.6071 - acc: 0.8644\n",
      "118/118 [==============================] - 0s 2ms/step\n",
      "\n",
      "acc: 92.37%\n",
      "Testing score for Neural Network :  0.966666666667\n",
      "Epoch 1/86\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 1.0814 - acc: 0.3983\n",
      "Epoch 2/86\n",
      "118/118 [==============================] - 0s 162us/step - loss: 1.0706 - acc: 0.4153\n",
      "Epoch 3/86\n",
      "118/118 [==============================] - 0s 266us/step - loss: 1.0662 - acc: 0.4407\n",
      "Epoch 4/86\n",
      "118/118 [==============================] - 0s 244us/step - loss: 1.0674 - acc: 0.4492\n",
      "Epoch 5/86\n",
      "118/118 [==============================] - 0s 207us/step - loss: 1.0723 - acc: 0.4153\n",
      "Epoch 6/86\n",
      "118/118 [==============================] - 0s 224us/step - loss: 1.0688 - acc: 0.4322\n",
      "Epoch 7/86\n",
      "118/118 [==============================] - 0s 200us/step - loss: 1.0345 - acc: 0.5424\n",
      "Epoch 8/86\n",
      "118/118 [==============================] - 0s 263us/step - loss: 1.0442 - acc: 0.4831\n",
      "Epoch 9/86\n",
      "118/118 [==============================] - 0s 437us/step - loss: 1.0575 - acc: 0.4322\n",
      "Epoch 10/86\n",
      "118/118 [==============================] - 0s 160us/step - loss: 1.0433 - acc: 0.4322\n",
      "Epoch 11/86\n",
      "118/118 [==============================] - 0s 132us/step - loss: 1.0248 - acc: 0.4831\n",
      "Epoch 12/86\n",
      "118/118 [==============================] - 0s 124us/step - loss: 1.0355 - acc: 0.4407\n",
      "Epoch 13/86\n",
      "118/118 [==============================] - 0s 129us/step - loss: 1.0366 - acc: 0.5000\n",
      "Epoch 14/86\n",
      "118/118 [==============================] - 0s 170us/step - loss: 1.0253 - acc: 0.4831\n",
      "Epoch 15/86\n",
      "118/118 [==============================] - 0s 232us/step - loss: 1.0276 - acc: 0.4576\n",
      "Epoch 16/86\n",
      "118/118 [==============================] - 0s 195us/step - loss: 1.0106 - acc: 0.5000\n",
      "Epoch 17/86\n",
      "118/118 [==============================] - 0s 196us/step - loss: 1.0170 - acc: 0.4492\n",
      "Epoch 18/86\n",
      "118/118 [==============================] - 0s 179us/step - loss: 1.0097 - acc: 0.5424\n",
      "Epoch 19/86\n",
      "118/118 [==============================] - 0s 200us/step - loss: 1.0132 - acc: 0.4831\n",
      "Epoch 20/86\n",
      "118/118 [==============================] - 0s 302us/step - loss: 1.0136 - acc: 0.4915\n",
      "Epoch 21/86\n",
      "118/118 [==============================] - 0s 159us/step - loss: 1.0081 - acc: 0.4831\n",
      "Epoch 22/86\n",
      "118/118 [==============================] - 0s 163us/step - loss: 0.9920 - acc: 0.5000\n",
      "Epoch 23/86\n",
      "118/118 [==============================] - 0s 168us/step - loss: 0.9821 - acc: 0.5424\n",
      "Epoch 24/86\n",
      "118/118 [==============================] - 0s 213us/step - loss: 0.9784 - acc: 0.5254\n",
      "Epoch 25/86\n",
      "118/118 [==============================] - 0s 195us/step - loss: 0.9841 - acc: 0.5169\n",
      "Epoch 26/86\n",
      "118/118 [==============================] - 0s 248us/step - loss: 0.9674 - acc: 0.5508\n",
      "Epoch 27/86\n",
      "118/118 [==============================] - 0s 453us/step - loss: 0.9647 - acc: 0.5254\n",
      "Epoch 28/86\n",
      "118/118 [==============================] - 0s 533us/step - loss: 0.9643 - acc: 0.4915\n",
      "Epoch 29/86\n",
      "118/118 [==============================] - 0s 363us/step - loss: 0.9699 - acc: 0.5000\n",
      "Epoch 30/86\n",
      "118/118 [==============================] - 0s 224us/step - loss: 0.9617 - acc: 0.4915\n",
      "Epoch 31/86\n",
      "118/118 [==============================] - 0s 177us/step - loss: 0.9543 - acc: 0.5424\n",
      "Epoch 32/86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 0s 205us/step - loss: 0.9481 - acc: 0.5424\n",
      "Epoch 33/86\n",
      "118/118 [==============================] - 0s 180us/step - loss: 0.9359 - acc: 0.5593\n",
      "Epoch 34/86\n",
      "118/118 [==============================] - 0s 155us/step - loss: 0.9415 - acc: 0.6017\n",
      "Epoch 35/86\n",
      "118/118 [==============================] - 0s 241us/step - loss: 0.9447 - acc: 0.4915\n",
      "Epoch 36/86\n",
      "118/118 [==============================] - 0s 250us/step - loss: 0.9367 - acc: 0.5678\n",
      "Epoch 37/86\n",
      "118/118 [==============================] - 0s 350us/step - loss: 0.9219 - acc: 0.5593\n",
      "Epoch 38/86\n",
      "118/118 [==============================] - 0s 153us/step - loss: 0.9228 - acc: 0.6017\n",
      "Epoch 39/86\n",
      "118/118 [==============================] - 0s 188us/step - loss: 0.9182 - acc: 0.5932\n",
      "Epoch 40/86\n",
      "118/118 [==============================] - 0s 193us/step - loss: 0.8930 - acc: 0.6525\n",
      "Epoch 41/86\n",
      "118/118 [==============================] - 0s 165us/step - loss: 0.8961 - acc: 0.6525\n",
      "Epoch 42/86\n",
      "118/118 [==============================] - 0s 166us/step - loss: 0.8943 - acc: 0.6610\n",
      "Epoch 43/86\n",
      "118/118 [==============================] - 0s 157us/step - loss: 0.8854 - acc: 0.6864\n",
      "Epoch 44/86\n",
      "118/118 [==============================] - 0s 309us/step - loss: 0.8869 - acc: 0.7034\n",
      "Epoch 45/86\n",
      "118/118 [==============================] - 0s 230us/step - loss: 0.8684 - acc: 0.6695\n",
      "Epoch 46/86\n",
      "118/118 [==============================] - 0s 192us/step - loss: 0.8688 - acc: 0.7288\n",
      "Epoch 47/86\n",
      "118/118 [==============================] - 0s 278us/step - loss: 0.8582 - acc: 0.7712\n",
      "Epoch 48/86\n",
      "118/118 [==============================] - 0s 263us/step - loss: 0.8556 - acc: 0.7288\n",
      "Epoch 49/86\n",
      "118/118 [==============================] - 0s 243us/step - loss: 0.8390 - acc: 0.7627\n",
      "Epoch 50/86\n",
      "118/118 [==============================] - 0s 260us/step - loss: 0.8316 - acc: 0.7288\n",
      "Epoch 51/86\n",
      "118/118 [==============================] - 0s 225us/step - loss: 0.8312 - acc: 0.7373\n",
      "Epoch 52/86\n",
      "118/118 [==============================] - 0s 127us/step - loss: 0.8322 - acc: 0.7373\n",
      "Epoch 53/86\n",
      "118/118 [==============================] - 0s 123us/step - loss: 0.8101 - acc: 0.7542\n",
      "Epoch 54/86\n",
      "118/118 [==============================] - 0s 130us/step - loss: 0.8136 - acc: 0.7458\n",
      "Epoch 55/86\n",
      "118/118 [==============================] - 0s 125us/step - loss: 0.7980 - acc: 0.8051\n",
      "Epoch 56/86\n",
      "118/118 [==============================] - 0s 224us/step - loss: 0.8076 - acc: 0.8305\n",
      "Epoch 57/86\n",
      "118/118 [==============================] - 0s 162us/step - loss: 0.7781 - acc: 0.8051\n",
      "Epoch 58/86\n",
      "118/118 [==============================] - 0s 146us/step - loss: 0.7854 - acc: 0.7966\n",
      "Epoch 59/86\n",
      "118/118 [==============================] - 0s 128us/step - loss: 0.7667 - acc: 0.8305\n",
      "Epoch 60/86\n",
      "118/118 [==============================] - 0s 121us/step - loss: 0.7694 - acc: 0.7542\n",
      "Epoch 61/86\n",
      "118/118 [==============================] - 0s 119us/step - loss: 0.7679 - acc: 0.7881\n",
      "Epoch 62/86\n",
      "118/118 [==============================] - 0s 119us/step - loss: 0.7495 - acc: 0.7712\n",
      "Epoch 63/86\n",
      "118/118 [==============================] - 0s 121us/step - loss: 0.7453 - acc: 0.8390\n",
      "Epoch 64/86\n",
      "118/118 [==============================] - 0s 155us/step - loss: 0.7345 - acc: 0.7966\n",
      "Epoch 65/86\n",
      "118/118 [==============================] - 0s 165us/step - loss: 0.7443 - acc: 0.8390\n",
      "Epoch 66/86\n",
      "118/118 [==============================] - 0s 157us/step - loss: 0.7327 - acc: 0.8559\n",
      "Epoch 67/86\n",
      "118/118 [==============================] - 0s 173us/step - loss: 0.7254 - acc: 0.8559\n",
      "Epoch 68/86\n",
      "118/118 [==============================] - 0s 191us/step - loss: 0.7197 - acc: 0.8390\n",
      "Epoch 69/86\n",
      "118/118 [==============================] - 0s 165us/step - loss: 0.7107 - acc: 0.8729\n",
      "Epoch 70/86\n",
      "118/118 [==============================] - 0s 170us/step - loss: 0.6979 - acc: 0.8729\n",
      "Epoch 71/86\n",
      "118/118 [==============================] - 0s 169us/step - loss: 0.6806 - acc: 0.8898\n",
      "Epoch 72/86\n",
      "118/118 [==============================] - 0s 168us/step - loss: 0.6870 - acc: 0.8559\n",
      "Epoch 73/86\n",
      "118/118 [==============================] - 0s 166us/step - loss: 0.6876 - acc: 0.8390\n",
      "Epoch 74/86\n",
      "118/118 [==============================] - 0s 160us/step - loss: 0.6819 - acc: 0.8644\n",
      "Epoch 75/86\n",
      "118/118 [==============================] - 0s 152us/step - loss: 0.6544 - acc: 0.8814\n",
      "Epoch 76/86\n",
      "118/118 [==============================] - 0s 184us/step - loss: 0.6620 - acc: 0.9068\n",
      "Epoch 77/86\n",
      "118/118 [==============================] - 0s 238us/step - loss: 0.6595 - acc: 0.8983\n",
      "Epoch 78/86\n",
      "118/118 [==============================] - 0s 271us/step - loss: 0.6556 - acc: 0.9068\n",
      "Epoch 79/86\n",
      "118/118 [==============================] - 0s 192us/step - loss: 0.6442 - acc: 0.9068\n",
      "Epoch 80/86\n",
      "118/118 [==============================] - 0s 262us/step - loss: 0.6393 - acc: 0.8729\n",
      "Epoch 81/86\n",
      "118/118 [==============================] - 0s 182us/step - loss: 0.6096 - acc: 0.8983\n",
      "Epoch 82/86\n",
      "118/118 [==============================] - 0s 184us/step - loss: 0.6029 - acc: 0.8898\n",
      "Epoch 83/86\n",
      "118/118 [==============================] - 0s 158us/step - loss: 0.6204 - acc: 0.9153\n",
      "Epoch 84/86\n",
      "118/118 [==============================] - 0s 165us/step - loss: 0.6167 - acc: 0.8983\n",
      "Epoch 85/86\n",
      "118/118 [==============================] - 0s 155us/step - loss: 0.5966 - acc: 0.9153\n",
      "Epoch 86/86\n",
      "118/118 [==============================] - 0s 218us/step - loss: 0.6247 - acc: 0.9068\n",
      "118/118 [==============================] - 0s 3ms/step\n",
      "\n",
      "acc: 94.07%\n",
      "Testing score for Neural Network :  0.95\n",
      "Epoch 1/91\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.1217 - acc: 0.3559\n",
      "Epoch 2/91\n",
      "118/118 [==============================] - 0s 123us/step - loss: 1.1207 - acc: 0.3559\n",
      "Epoch 3/91\n",
      "118/118 [==============================] - 0s 121us/step - loss: 1.1042 - acc: 0.3559\n",
      "Epoch 4/91\n",
      "118/118 [==============================] - 0s 126us/step - loss: 1.0969 - acc: 0.3644\n",
      "Epoch 5/91\n",
      "118/118 [==============================] - 0s 121us/step - loss: 1.0908 - acc: 0.4153\n",
      "Epoch 6/91\n",
      "118/118 [==============================] - 0s 114us/step - loss: 1.0919 - acc: 0.4407\n",
      "Epoch 7/91\n",
      "118/118 [==============================] - 0s 122us/step - loss: 1.0683 - acc: 0.4407\n",
      "Epoch 8/91\n",
      "118/118 [==============================] - 0s 124us/step - loss: 1.0579 - acc: 0.4407\n",
      "Epoch 9/91\n",
      "118/118 [==============================] - 0s 124us/step - loss: 1.0573 - acc: 0.3814\n",
      "Epoch 10/91\n",
      "118/118 [==============================] - 0s 112us/step - loss: 1.0659 - acc: 0.4153\n",
      "Epoch 11/91\n",
      "118/118 [==============================] - 0s 116us/step - loss: 1.0546 - acc: 0.4068\n",
      "Epoch 12/91\n",
      "118/118 [==============================] - 0s 127us/step - loss: 1.0458 - acc: 0.4576\n",
      "Epoch 13/91\n",
      "118/118 [==============================] - 0s 121us/step - loss: 1.0686 - acc: 0.3983\n",
      "Epoch 14/91\n",
      "118/118 [==============================] - 0s 126us/step - loss: 1.0398 - acc: 0.4576\n",
      "Epoch 15/91\n",
      "118/118 [==============================] - 0s 118us/step - loss: 1.0467 - acc: 0.4576\n",
      "Epoch 16/91\n",
      "118/118 [==============================] - 0s 126us/step - loss: 1.0254 - acc: 0.4661\n",
      "Epoch 17/91\n",
      "118/118 [==============================] - 0s 122us/step - loss: 1.0444 - acc: 0.4661\n",
      "Epoch 18/91\n",
      "118/118 [==============================] - 0s 115us/step - loss: 1.0333 - acc: 0.4407\n",
      "Epoch 19/91\n",
      "118/118 [==============================] - 0s 120us/step - loss: 1.0242 - acc: 0.4831\n",
      "Epoch 20/91\n",
      "118/118 [==============================] - 0s 125us/step - loss: 1.0243 - acc: 0.4915\n",
      "Epoch 21/91\n",
      "118/118 [==============================] - 0s 133us/step - loss: 1.0343 - acc: 0.4492\n",
      "Epoch 22/91\n",
      "118/118 [==============================] - 0s 124us/step - loss: 1.0120 - acc: 0.4831\n",
      "Epoch 23/91\n",
      "118/118 [==============================] - 0s 128us/step - loss: 1.0152 - acc: 0.5169\n",
      "Epoch 24/91\n",
      "118/118 [==============================] - 0s 124us/step - loss: 1.0061 - acc: 0.4407\n",
      "Epoch 25/91\n",
      "118/118 [==============================] - 0s 176us/step - loss: 1.0028 - acc: 0.4831\n",
      "Epoch 26/91\n",
      "118/118 [==============================] - 0s 129us/step - loss: 1.0034 - acc: 0.5169\n",
      "Epoch 27/91\n",
      "118/118 [==============================] - 0s 125us/step - loss: 1.0043 - acc: 0.4661\n",
      "Epoch 28/91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 0s 124us/step - loss: 1.0140 - acc: 0.4746\n",
      "Epoch 29/91\n",
      "118/118 [==============================] - 0s 125us/step - loss: 0.9955 - acc: 0.4831\n",
      "Epoch 30/91\n",
      "118/118 [==============================] - 0s 129us/step - loss: 0.9766 - acc: 0.5508\n",
      "Epoch 31/91\n",
      "118/118 [==============================] - 0s 125us/step - loss: 0.9811 - acc: 0.5169\n",
      "Epoch 32/91\n",
      "118/118 [==============================] - 0s 124us/step - loss: 0.9735 - acc: 0.5254\n",
      "Epoch 33/91\n",
      "118/118 [==============================] - 0s 124us/step - loss: 0.9652 - acc: 0.5508\n",
      "Epoch 34/91\n",
      "118/118 [==============================] - 0s 123us/step - loss: 0.9856 - acc: 0.4746\n",
      "Epoch 35/91\n",
      "118/118 [==============================] - 0s 119us/step - loss: 0.9598 - acc: 0.5339\n",
      "Epoch 36/91\n",
      "118/118 [==============================] - 0s 115us/step - loss: 0.9657 - acc: 0.5678\n",
      "Epoch 37/91\n",
      "118/118 [==============================] - 0s 117us/step - loss: 0.9511 - acc: 0.5508\n",
      "Epoch 38/91\n",
      "118/118 [==============================] - 0s 120us/step - loss: 0.9352 - acc: 0.6017\n",
      "Epoch 39/91\n",
      "118/118 [==============================] - 0s 117us/step - loss: 0.9311 - acc: 0.5932\n",
      "Epoch 40/91\n",
      "118/118 [==============================] - 0s 118us/step - loss: 0.9412 - acc: 0.5932\n",
      "Epoch 41/91\n",
      "118/118 [==============================] - 0s 129us/step - loss: 0.9437 - acc: 0.5678\n",
      "Epoch 42/91\n",
      "118/118 [==============================] - 0s 116us/step - loss: 0.9255 - acc: 0.6186\n",
      "Epoch 43/91\n",
      "118/118 [==============================] - 0s 129us/step - loss: 0.9149 - acc: 0.6186\n",
      "Epoch 44/91\n",
      "118/118 [==============================] - 0s 131us/step - loss: 0.9250 - acc: 0.6441\n",
      "Epoch 45/91\n",
      "118/118 [==============================] - 0s 115us/step - loss: 0.9037 - acc: 0.6441\n",
      "Epoch 46/91\n",
      "118/118 [==============================] - 0s 123us/step - loss: 0.9003 - acc: 0.6356\n",
      "Epoch 47/91\n",
      "118/118 [==============================] - 0s 129us/step - loss: 0.8977 - acc: 0.6525\n",
      "Epoch 48/91\n",
      "118/118 [==============================] - 0s 124us/step - loss: 0.8784 - acc: 0.6525\n",
      "Epoch 49/91\n",
      "118/118 [==============================] - 0s 125us/step - loss: 0.8972 - acc: 0.6610\n",
      "Epoch 50/91\n",
      "118/118 [==============================] - 0s 128us/step - loss: 0.8830 - acc: 0.7034\n",
      "Epoch 51/91\n",
      "118/118 [==============================] - 0s 121us/step - loss: 0.8744 - acc: 0.6610\n",
      "Epoch 52/91\n",
      "118/118 [==============================] - 0s 131us/step - loss: 0.8521 - acc: 0.7288\n",
      "Epoch 53/91\n",
      "118/118 [==============================] - 0s 126us/step - loss: 0.8744 - acc: 0.6949\n",
      "Epoch 54/91\n",
      "118/118 [==============================] - 0s 120us/step - loss: 0.8566 - acc: 0.6780\n",
      "Epoch 55/91\n",
      "118/118 [==============================] - 0s 121us/step - loss: 0.8380 - acc: 0.6949\n",
      "Epoch 56/91\n",
      "118/118 [==============================] - 0s 118us/step - loss: 0.8329 - acc: 0.7288\n",
      "Epoch 57/91\n",
      "118/118 [==============================] - 0s 119us/step - loss: 0.8315 - acc: 0.7458\n",
      "Epoch 58/91\n",
      "118/118 [==============================] - 0s 115us/step - loss: 0.8207 - acc: 0.7881\n",
      "Epoch 59/91\n",
      "118/118 [==============================] - 0s 119us/step - loss: 0.8066 - acc: 0.8390\n",
      "Epoch 60/91\n",
      "118/118 [==============================] - 0s 133us/step - loss: 0.8135 - acc: 0.8051\n",
      "Epoch 61/91\n",
      "118/118 [==============================] - 0s 122us/step - loss: 0.8088 - acc: 0.8051\n",
      "Epoch 62/91\n",
      "118/118 [==============================] - 0s 133us/step - loss: 0.7915 - acc: 0.8390\n",
      "Epoch 63/91\n",
      "118/118 [==============================] - 0s 125us/step - loss: 0.8035 - acc: 0.8305\n",
      "Epoch 64/91\n",
      "118/118 [==============================] - 0s 121us/step - loss: 0.7700 - acc: 0.8390\n",
      "Epoch 65/91\n",
      "118/118 [==============================] - 0s 121us/step - loss: 0.7644 - acc: 0.8305\n",
      "Epoch 66/91\n",
      "118/118 [==============================] - 0s 127us/step - loss: 0.7627 - acc: 0.8136\n",
      "Epoch 67/91\n",
      "118/118 [==============================] - 0s 143us/step - loss: 0.7600 - acc: 0.7881\n",
      "Epoch 68/91\n",
      "118/118 [==============================] - 0s 120us/step - loss: 0.7588 - acc: 0.7966\n",
      "Epoch 69/91\n",
      "118/118 [==============================] - 0s 122us/step - loss: 0.7470 - acc: 0.8051\n",
      "Epoch 70/91\n",
      "118/118 [==============================] - 0s 119us/step - loss: 0.7303 - acc: 0.8051\n",
      "Epoch 71/91\n",
      "118/118 [==============================] - 0s 118us/step - loss: 0.7132 - acc: 0.8136\n",
      "Epoch 72/91\n",
      "118/118 [==============================] - 0s 136us/step - loss: 0.7226 - acc: 0.8475\n",
      "Epoch 73/91\n",
      "118/118 [==============================] - 0s 141us/step - loss: 0.7217 - acc: 0.8390\n",
      "Epoch 74/91\n",
      "118/118 [==============================] - 0s 151us/step - loss: 0.7114 - acc: 0.8814\n",
      "Epoch 75/91\n",
      "118/118 [==============================] - 0s 316us/step - loss: 0.6905 - acc: 0.8983\n",
      "Epoch 76/91\n",
      "118/118 [==============================] - 0s 218us/step - loss: 0.6920 - acc: 0.8729\n",
      "Epoch 77/91\n",
      "118/118 [==============================] - 0s 221us/step - loss: 0.7074 - acc: 0.8898\n",
      "Epoch 78/91\n",
      "118/118 [==============================] - 0s 168us/step - loss: 0.6810 - acc: 0.8559\n",
      "Epoch 79/91\n",
      "118/118 [==============================] - 0s 212us/step - loss: 0.6841 - acc: 0.8814\n",
      "Epoch 80/91\n",
      "118/118 [==============================] - 0s 199us/step - loss: 0.6795 - acc: 0.8814\n",
      "Epoch 81/91\n",
      "118/118 [==============================] - 0s 224us/step - loss: 0.6563 - acc: 0.8729\n",
      "Epoch 82/91\n",
      "118/118 [==============================] - 0s 175us/step - loss: 0.6748 - acc: 0.8729\n",
      "Epoch 83/91\n",
      "118/118 [==============================] - 0s 188us/step - loss: 0.6500 - acc: 0.8559\n",
      "Epoch 84/91\n",
      "118/118 [==============================] - 0s 189us/step - loss: 0.6434 - acc: 0.8729\n",
      "Epoch 85/91\n",
      "118/118 [==============================] - 0s 219us/step - loss: 0.6412 - acc: 0.8983\n",
      "Epoch 86/91\n",
      "118/118 [==============================] - 0s 180us/step - loss: 0.6473 - acc: 0.8559\n",
      "Epoch 87/91\n",
      "118/118 [==============================] - 0s 245us/step - loss: 0.6338 - acc: 0.8729\n",
      "Epoch 88/91\n",
      "118/118 [==============================] - 0s 168us/step - loss: 0.6294 - acc: 0.8729\n",
      "Epoch 89/91\n",
      "118/118 [==============================] - 0s 220us/step - loss: 0.6227 - acc: 0.8475\n",
      "Epoch 90/91\n",
      "118/118 [==============================] - 0s 165us/step - loss: 0.6178 - acc: 0.8729\n",
      "Epoch 91/91\n",
      "118/118 [==============================] - 0s 166us/step - loss: 0.5991 - acc: 0.9153\n",
      "118/118 [==============================] - 0s 2ms/step\n",
      "\n",
      "acc: 94.07%\n",
      "Testing score for Neural Network :  0.933333333333\n",
      "Epoch 1/96\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 1.1121 - acc: 0.3898\n",
      "Epoch 2/96\n",
      "118/118 [==============================] - 0s 133us/step - loss: 1.1034 - acc: 0.3898\n",
      "Epoch 3/96\n",
      "118/118 [==============================] - 0s 128us/step - loss: 1.1052 - acc: 0.4407\n",
      "Epoch 4/96\n",
      "118/118 [==============================] - 0s 130us/step - loss: 1.0827 - acc: 0.4237\n",
      "Epoch 5/96\n",
      "118/118 [==============================] - 0s 138us/step - loss: 1.0791 - acc: 0.4153\n",
      "Epoch 6/96\n",
      "118/118 [==============================] - 0s 122us/step - loss: 1.0739 - acc: 0.4237\n",
      "Epoch 7/96\n",
      "118/118 [==============================] - 0s 128us/step - loss: 1.0733 - acc: 0.4322\n",
      "Epoch 8/96\n",
      "118/118 [==============================] - 0s 126us/step - loss: 1.0627 - acc: 0.4407\n",
      "Epoch 9/96\n",
      "118/118 [==============================] - 0s 126us/step - loss: 1.0669 - acc: 0.4237\n",
      "Epoch 10/96\n",
      "118/118 [==============================] - 0s 197us/step - loss: 1.0753 - acc: 0.3983\n",
      "Epoch 11/96\n",
      "118/118 [==============================] - 0s 200us/step - loss: 1.0616 - acc: 0.4068\n",
      "Epoch 12/96\n",
      "118/118 [==============================] - 0s 189us/step - loss: 1.0547 - acc: 0.4153\n",
      "Epoch 13/96\n",
      "118/118 [==============================] - 0s 202us/step - loss: 1.0645 - acc: 0.4153\n",
      "Epoch 14/96\n",
      "118/118 [==============================] - 0s 181us/step - loss: 1.0456 - acc: 0.4407\n",
      "Epoch 15/96\n",
      "118/118 [==============================] - 0s 259us/step - loss: 1.0387 - acc: 0.4237\n",
      "Epoch 16/96\n",
      "118/118 [==============================] - 0s 193us/step - loss: 1.0368 - acc: 0.4322\n",
      "Epoch 17/96\n",
      "118/118 [==============================] - 0s 198us/step - loss: 1.0482 - acc: 0.4576\n",
      "Epoch 18/96\n",
      "118/118 [==============================] - 0s 167us/step - loss: 1.0364 - acc: 0.4576\n",
      "Epoch 19/96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 0s 138us/step - loss: 1.0338 - acc: 0.4407\n",
      "Epoch 20/96\n",
      "118/118 [==============================] - 0s 128us/step - loss: 1.0260 - acc: 0.4661\n",
      "Epoch 21/96\n",
      "118/118 [==============================] - 0s 118us/step - loss: 1.0205 - acc: 0.4831\n",
      "Epoch 22/96\n",
      "118/118 [==============================] - 0s 120us/step - loss: 1.0203 - acc: 0.4576\n",
      "Epoch 23/96\n",
      "118/118 [==============================] - 0s 120us/step - loss: 1.0264 - acc: 0.4746\n",
      "Epoch 24/96\n",
      "118/118 [==============================] - 0s 115us/step - loss: 1.0046 - acc: 0.4576\n",
      "Epoch 25/96\n",
      "118/118 [==============================] - 0s 124us/step - loss: 0.9969 - acc: 0.4915\n",
      "Epoch 26/96\n",
      "118/118 [==============================] - 0s 118us/step - loss: 1.0124 - acc: 0.4322\n",
      "Epoch 27/96\n",
      "118/118 [==============================] - 0s 130us/step - loss: 0.9984 - acc: 0.5169\n",
      "Epoch 28/96\n",
      "118/118 [==============================] - 0s 124us/step - loss: 0.9959 - acc: 0.5085\n",
      "Epoch 29/96\n",
      "118/118 [==============================] - 0s 130us/step - loss: 0.9839 - acc: 0.5085\n",
      "Epoch 30/96\n",
      "118/118 [==============================] - 0s 130us/step - loss: 0.9760 - acc: 0.5254\n",
      "Epoch 31/96\n",
      "118/118 [==============================] - 0s 116us/step - loss: 0.9757 - acc: 0.5593\n",
      "Epoch 32/96\n",
      "118/118 [==============================] - 0s 127us/step - loss: 0.9697 - acc: 0.5254\n",
      "Epoch 33/96\n",
      "118/118 [==============================] - 0s 121us/step - loss: 0.9716 - acc: 0.4237\n",
      "Epoch 34/96\n",
      "118/118 [==============================] - 0s 122us/step - loss: 0.9699 - acc: 0.4915\n",
      "Epoch 35/96\n",
      "118/118 [==============================] - 0s 122us/step - loss: 0.9646 - acc: 0.5254\n",
      "Epoch 36/96\n",
      "118/118 [==============================] - 0s 118us/step - loss: 0.9676 - acc: 0.5932\n",
      "Epoch 37/96\n",
      "118/118 [==============================] - 0s 120us/step - loss: 0.9558 - acc: 0.5424\n",
      "Epoch 38/96\n",
      "118/118 [==============================] - 0s 127us/step - loss: 0.9326 - acc: 0.6441\n",
      "Epoch 39/96\n",
      "118/118 [==============================] - 0s 120us/step - loss: 0.9335 - acc: 0.6356\n",
      "Epoch 40/96\n",
      "118/118 [==============================] - 0s 118us/step - loss: 0.9200 - acc: 0.5932\n",
      "Epoch 41/96\n",
      "118/118 [==============================] - 0s 121us/step - loss: 0.9310 - acc: 0.6441\n",
      "Epoch 42/96\n",
      "118/118 [==============================] - 0s 151us/step - loss: 0.9261 - acc: 0.6271\n",
      "Epoch 43/96\n",
      "118/118 [==============================] - 0s 236us/step - loss: 0.9033 - acc: 0.6017\n",
      "Epoch 44/96\n",
      "118/118 [==============================] - 0s 266us/step - loss: 0.9021 - acc: 0.6441\n",
      "Epoch 45/96\n",
      "118/118 [==============================] - 0s 273us/step - loss: 0.9043 - acc: 0.6864\n",
      "Epoch 46/96\n",
      "118/118 [==============================] - 0s 315us/step - loss: 0.9014 - acc: 0.6610\n",
      "Epoch 47/96\n",
      "118/118 [==============================] - 0s 334us/step - loss: 0.8831 - acc: 0.7034\n",
      "Epoch 48/96\n",
      "118/118 [==============================] - 0s 386us/step - loss: 0.8886 - acc: 0.6864\n",
      "Epoch 49/96\n",
      "118/118 [==============================] - 0s 238us/step - loss: 0.8865 - acc: 0.6441\n",
      "Epoch 50/96\n",
      "118/118 [==============================] - 0s 140us/step - loss: 0.8821 - acc: 0.6271\n",
      "Epoch 51/96\n",
      "118/118 [==============================] - 0s 153us/step - loss: 0.8561 - acc: 0.7034\n",
      "Epoch 52/96\n",
      "118/118 [==============================] - 0s 146us/step - loss: 0.8564 - acc: 0.6949\n",
      "Epoch 53/96\n",
      "118/118 [==============================] - 0s 128us/step - loss: 0.8577 - acc: 0.6780\n",
      "Epoch 54/96\n",
      "118/118 [==============================] - 0s 136us/step - loss: 0.8587 - acc: 0.6780\n",
      "Epoch 55/96\n",
      "118/118 [==============================] - 0s 138us/step - loss: 0.8406 - acc: 0.7203\n",
      "Epoch 56/96\n",
      "118/118 [==============================] - 0s 142us/step - loss: 0.8177 - acc: 0.8051\n",
      "Epoch 57/96\n",
      "118/118 [==============================] - 0s 148us/step - loss: 0.8099 - acc: 0.8220\n",
      "Epoch 58/96\n",
      "118/118 [==============================] - 0s 140us/step - loss: 0.8223 - acc: 0.7797\n",
      "Epoch 59/96\n",
      "118/118 [==============================] - 0s 143us/step - loss: 0.8025 - acc: 0.8305\n",
      "Epoch 60/96\n",
      "118/118 [==============================] - 0s 135us/step - loss: 0.8074 - acc: 0.8220\n",
      "Epoch 61/96\n",
      "118/118 [==============================] - 0s 147us/step - loss: 0.7860 - acc: 0.8220\n",
      "Epoch 62/96\n",
      "118/118 [==============================] - 0s 142us/step - loss: 0.8065 - acc: 0.7966\n",
      "Epoch 63/96\n",
      "118/118 [==============================] - 0s 137us/step - loss: 0.7751 - acc: 0.8475\n",
      "Epoch 64/96\n",
      "118/118 [==============================] - 0s 130us/step - loss: 0.7795 - acc: 0.8136\n",
      "Epoch 65/96\n",
      "118/118 [==============================] - 0s 129us/step - loss: 0.7943 - acc: 0.7966\n",
      "Epoch 66/96\n",
      "118/118 [==============================] - 0s 131us/step - loss: 0.7349 - acc: 0.8644\n",
      "Epoch 67/96\n",
      "118/118 [==============================] - 0s 129us/step - loss: 0.7432 - acc: 0.8305\n",
      "Epoch 68/96\n",
      "118/118 [==============================] - 0s 133us/step - loss: 0.7486 - acc: 0.8475\n",
      "Epoch 69/96\n",
      "118/118 [==============================] - 0s 207us/step - loss: 0.7433 - acc: 0.7797\n",
      "Epoch 70/96\n",
      "118/118 [==============================] - 0s 202us/step - loss: 0.7237 - acc: 0.8390\n",
      "Epoch 71/96\n",
      "118/118 [==============================] - 0s 171us/step - loss: 0.7234 - acc: 0.8814\n",
      "Epoch 72/96\n",
      "118/118 [==============================] - 0s 196us/step - loss: 0.7016 - acc: 0.8898\n",
      "Epoch 73/96\n",
      "118/118 [==============================] - 0s 185us/step - loss: 0.6906 - acc: 0.8814\n",
      "Epoch 74/96\n",
      "118/118 [==============================] - 0s 232us/step - loss: 0.7175 - acc: 0.8220\n",
      "Epoch 75/96\n",
      "118/118 [==============================] - 0s 207us/step - loss: 0.6838 - acc: 0.8136\n",
      "Epoch 76/96\n",
      "118/118 [==============================] - 0s 195us/step - loss: 0.7049 - acc: 0.8729\n",
      "Epoch 77/96\n",
      "118/118 [==============================] - 0s 176us/step - loss: 0.6830 - acc: 0.8644\n",
      "Epoch 78/96\n",
      "118/118 [==============================] - 0s 153us/step - loss: 0.6714 - acc: 0.8814\n",
      "Epoch 79/96\n",
      "118/118 [==============================] - 0s 164us/step - loss: 0.6775 - acc: 0.8559\n",
      "Epoch 80/96\n",
      "118/118 [==============================] - 0s 131us/step - loss: 0.6585 - acc: 0.9153\n",
      "Epoch 81/96\n",
      "118/118 [==============================] - 0s 128us/step - loss: 0.6631 - acc: 0.8729\n",
      "Epoch 82/96\n",
      "118/118 [==============================] - 0s 134us/step - loss: 0.6593 - acc: 0.8729\n",
      "Epoch 83/96\n",
      "118/118 [==============================] - 0s 125us/step - loss: 0.6339 - acc: 0.8814\n",
      "Epoch 84/96\n",
      "118/118 [==============================] - 0s 123us/step - loss: 0.6273 - acc: 0.9153\n",
      "Epoch 85/96\n",
      "118/118 [==============================] - 0s 121us/step - loss: 0.6263 - acc: 0.9068\n",
      "Epoch 86/96\n",
      "118/118 [==============================] - 0s 133us/step - loss: 0.6287 - acc: 0.8898\n",
      "Epoch 87/96\n",
      "118/118 [==============================] - 0s 122us/step - loss: 0.6133 - acc: 0.8729\n",
      "Epoch 88/96\n",
      "118/118 [==============================] - 0s 127us/step - loss: 0.5949 - acc: 0.8898\n",
      "Epoch 89/96\n",
      "118/118 [==============================] - 0s 127us/step - loss: 0.5917 - acc: 0.9068\n",
      "Epoch 90/96\n",
      "118/118 [==============================] - 0s 130us/step - loss: 0.5856 - acc: 0.9068\n",
      "Epoch 91/96\n",
      "118/118 [==============================] - 0s 126us/step - loss: 0.5939 - acc: 0.9068\n",
      "Epoch 92/96\n",
      "118/118 [==============================] - 0s 125us/step - loss: 0.5891 - acc: 0.8983\n",
      "Epoch 93/96\n",
      "118/118 [==============================] - 0s 119us/step - loss: 0.5734 - acc: 0.9068\n",
      "Epoch 94/96\n",
      "118/118 [==============================] - 0s 135us/step - loss: 0.5652 - acc: 0.8814\n",
      "Epoch 95/96\n",
      "118/118 [==============================] - 0s 139us/step - loss: 0.5896 - acc: 0.8983\n",
      "Epoch 96/96\n",
      "118/118 [==============================] - 0s 150us/step - loss: 0.5680 - acc: 0.9153\n",
      "118/118 [==============================] - 0s 2ms/step\n",
      "\n",
      "acc: 94.07%\n",
      "Testing score for Neural Network :  0.95\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEWCAYAAACT7WsrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fce745c87d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time in 45.215726s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "training_score = []\n",
    "testing_score = []\n",
    "nb_epochs = range(1,100,5)\n",
    "for k in nb_epochs:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, activation='tanh', input_dim=13))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_dummies2, epochs=k, batch_size=10)\n",
    "    #y_pred_train = model.predict(X_train)\n",
    "    #y_pred_test = model.predict(X_test)\n",
    "    #print'Training score for Neural Network : ', accuracy_score(y_pred_train, y_train)\n",
    "    #print'Testing score for Neural Network : ', accuracy_score(y_pred_test, y_test)\n",
    "    scores = model.evaluate(X_train, y_dummies2)\n",
    "    training_score.append(scores[1])\n",
    "    print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    y_pred_test = []\n",
    "    for i in range(len(predictions)):\n",
    "        y_pred_test.append(np.argmax(predictions[i])+1)\n",
    "    testing_score.append(accuracy_score(y_pred_test, y_test))\n",
    "    print'Testing score for Neural Network : ', accuracy_score(y_pred_test, y_test)\n",
    "plt.figure()\n",
    "plt.plot(nb_epochs, training_score, label='Training score')\n",
    "plt.plot(nb_epochs, testing_score, label='Testing score')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Accuracy score')\n",
    "plt.title('Score for Neural Network')\n",
    "plt.savefig('Neural_Network.png')\n",
    "plt.show()\n",
    "print'Time in %fs' % (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_score)\n",
    "print(len(testing_score))\n",
    "new_train = training_score\n",
    "new_test = testing_score\n",
    "new_epo = nb_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del new_train[21]\n",
    "del new_test[21]\n",
    "del new_epo[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del new_train[56]\n",
    "del new_test[56]\n",
    "del new_epo[56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(new_epo, new_train, label='Training score')\n",
    "plt.plot(new_epo, new_test, label='Testing score')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Score for Neural Network')\n",
    "plt.savefig('bite.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
